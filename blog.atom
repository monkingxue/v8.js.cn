<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>V8</title>
  <subtitle>JavaScript V8 引擎</subtitle>
  <link href="https://v8.js.cn/blog.atom" rel="self"/>
  <link href="https://v8.js.cn/"/>
  <updated>2015-07-10T13:33:37+00:00</updated>
  <id>https://v8.js.cn/</id>
  <author>
    <name>Mathias Bynens</name>
  </author>
  
  <entry>
    <title>V8 v7.1 发布</title>
    <link href="https://v8.js.cn/blog/v8-release-71"/>
    <updated>2018-10-31T15:44:37+00:00</updated>
    <id>https://v8.js.cn/blog/v8-release-71</id>
    <author>
      <name>Stephan Herhut (@herhut), cloned cloner of clones</name>
    </author>
    <content type="html">&lt;p&gt;每六周，我们会按照 &lt;a href=&quot;https://v8.js.cn/docs/release-process&quot;&gt;V8 的发布流程&lt;/a&gt;创建一个新的 V8 分支。在进入 Chrome Beta 里程碑之前，此版本从 V8 的 master 分支创建出来。今天我们很高兴地宣布当前最新的分支异常创建出来了，&lt;a href=&quot;https://chromium.googlesource.com/v8/v8.git/+log/branch-heads/7.1&quot;&gt;V8 version 7.1&lt;/a&gt;，它将在几个星期内与 Chrome 71 Stable 同时发布。V8 v7.1 包含了各种面向开发者的新特性。这篇文章提供了预期发布的一些功能亮点。&lt;/p&gt;
&lt;h2 id=&quot;memory&quot;&gt;内存 &lt;a class=&quot;bookmark&quot; href=&quot;#memory&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;在 v6.9/v7.0 中&lt;a href=&quot;https://v8.js.cn/blog/embedded-builtins&quot;&gt;将内置函数直接以二进制方式嵌入&lt;/a&gt;后，解释器的字节码处理程序现在也&lt;a href=&quot;https://bugs.chromium.org/p/v8/issues/detail?id=8068&quot;&gt;嵌入到二进制文件中&lt;/a&gt;。每个 Isolate 平均节省大约 200 KB。&lt;/p&gt;
&lt;h2 id=&quot;performance&quot;&gt;性能 &lt;a class=&quot;bookmark&quot; href=&quot;#performance&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;TurboFan 中的逃逸分析（对局部作用域的对象执行标量替换）得到了改进，当来自周围上下文的变量转移到本地闭包时，它还能够&lt;a href=&quot;https://bit.ly/v8-turbofan-context-sensitive-js-operators&quot;&gt;处理高阶函数的局部函数上下文&lt;/a&gt;。请考虑以下示例：&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;mapAdd&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;a&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; a&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;y &lt;span class=&quot;token operator&quot;&gt;=&gt;&lt;/span&gt; y &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意，这里的 &lt;code&gt;x&lt;/code&gt; 是局部作用域闭包 &lt;code&gt;y =&amp;gt; y + x&lt;/code&gt; 的自由变量。V8 v7.1 现在可以完全忽略上下文中分配的 &lt;code&gt;x&lt;/code&gt;，在某些情况下可以提高 40%。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/v8-release-71/improved-escape-analysis.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;通过新的逃逸分析提升性能（越低越好）&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;逃逸分析现在还能够消除使用变量作为索引访问局部数据的行为。下面是一个例子：&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;...&lt;/span&gt;args&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; total &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; args&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;length&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    total &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; args&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; total&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sum2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; y&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; y&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;请注意，&lt;code&gt;args&lt;/code&gt; 是 &lt;code&gt;sum2&lt;/code&gt; 的局部变量（假设 &lt;code&gt;sum&lt;/code&gt; 被内联进了 &lt;code&gt;sum2&lt;/code&gt;）。在 V8 v7.1 中，TurboFan 现在可以把 &lt;code&gt;args&lt;/code&gt; 完全消除，并使用三元操作 &lt;code&gt;i === 0 ? x : y&lt;/code&gt; 替换变量索引访问操作 &lt;code&gt;args[i]&lt;/code&gt;。在使用 JetStream/EarleyBoyer 进行基准测试时，性能提高了约 2%。我们将来会继续扩展此优化，使具有两个以上元素的数组也可以进行类似优化。&lt;/p&gt;
&lt;h2 id=&quot;structured-cloning-of-wasm-modules&quot;&gt;Wasm modules 的结构化克隆 &lt;a class=&quot;bookmark&quot; href=&quot;#structured-cloning-of-wasm-modules&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;最后，&lt;a href=&quot;https://github.com/WebAssembly/design/pull/1074&quot;&gt;&lt;code&gt;postMessage&lt;/code&gt; is supported for Wasm modules&lt;/a&gt;。&lt;code&gt;WebAssembly.Module&lt;/code&gt; 对象现在可以被 &lt;code&gt;postMessage&lt;/code&gt; 发送到 web workers。为了更加清晰，这仅限于 web workers（相同的进程，不同的线程），而不能扩展到跨进程场景（例如跨域(cross-origin) &lt;code&gt;postMessage&lt;/code&gt; 或 shared web workers）。&lt;/p&gt;
&lt;h2 id=&quot;javascript-language-features&quot;&gt;JavaScript 语言新特性 &lt;a class=&quot;bookmark&quot; href=&quot;#javascript-language-features&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/47417391&quot;&gt;&lt;code&gt;Intl.RelativeTimeFormat&lt;/code&gt; API&lt;/a&gt; 可以让我们处理相对时间的本地化格式（例如，“昨天”，“42秒前”或“3个月”），而不牺牲性能。下面是一个例子：&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// 创建一个本地化相对时间，中文&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; rtf &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Intl&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;RelativeTimeFormat&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;zh&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; numeric&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;auto&#39;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;rtf&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;day&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;昨天&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;rtf&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;day&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;今天&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;rtf&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;day&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;明天&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;rtf&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;week&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;上周&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;rtf&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;week&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;本周&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;rtf&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;week&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;下周&#39;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;有关 &lt;code&gt;Intl.RelativeTimeFormat&lt;/code&gt; 的更多信息，请阅读 Google Web Fundamentals 的 &lt;a href=&quot;https://developers.google.com/web/updates/2018/10/intl-relativetimeformat&quot;&gt;The Intl.RelativeTimeFormat API&lt;/a&gt; 文章，中文翻译版&lt;a href=&quot;https://zhuanlan.zhihu.com/p/47417391&quot;&gt;国际化相对时间格式化API：Intl.RelativeTimeFormat&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;V8 v7.1 还增加了对 &lt;a href=&quot;https://github.com/tc39/proposal-global&quot;&gt;&lt;code&gt;globalThis&lt;/code&gt; 提案&lt;/a&gt;的支持，此提案提供了访问全局对象的通用机制，即使在严格模式的函数或模块中，而不管平台如何。&lt;/p&gt;
&lt;h2 id=&quot;v8-api&quot;&gt;V8 API &lt;a class=&quot;bookmark&quot; href=&quot;#v8-api&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;请使用 &lt;code&gt;git log branch-heads/7.0..branch-heads/7.1 include/v8.h&lt;/code&gt; 获取 API 的变更列表。&lt;/p&gt;
&lt;p&gt;开发者可以使用 &lt;code&gt;git checkout -b 7.1 -t branch-heads/7.1&lt;/code&gt; 来使用 V8 v7.1 中的实验性新功能，具体请参阅&lt;a href=&quot;https://v8.js.cn/docs/source-code#using-git&quot;&gt;使用 Git 获取 V8 源码&lt;/a&gt;。或者，您可以订阅 &lt;a href=&quot;https://www.google.com/chrome/browser/beta.html&quot;&gt;Chrome 的 Beta 频道&lt;/a&gt; 来尽快尝试新功能。&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>V8 release v7.0</title>
    <link href="https://v8.js.cn/blog/v8-release-70"/>
    <updated>2018-10-15T17:17:00+00:00</updated>
    <id>https://v8.js.cn/blog/v8-release-70</id>
    <author>
      <name>Michael Hablich</name>
    </author>
    <content type="html">&lt;p&gt;Every six weeks, we create a new branch of V8 as part of our &lt;a href=&quot;https://github.com/v8/v8/wiki/Release-Process&quot;&gt;release process&lt;/a&gt;. Each version is branched from V8’s Git master immediately before a Chrome Beta milestone. Today we’re pleased to announce our newest branch, &lt;a href=&quot;https://chromium.googlesource.com/v8/v8.git/+log/branch-heads/7.0&quot;&gt;V8 version 7.0&lt;/a&gt;, which is in beta until its release in coordination with Chrome 70 Stable in several weeks. V8 v7.0 is filled with all sorts of developer-facing goodies. This post provides a preview of some of the highlights in anticipation of the release.&lt;/p&gt;
&lt;h2 id=&quot;embedded-built-ins&quot;&gt;Embedded built-ins &lt;a class=&quot;bookmark&quot; href=&quot;#embedded-built-ins&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://v8.js.cn/blog/embedded-builtins&quot;&gt;Embedded builtins&lt;/a&gt; save memory by sharing generated code across multiple V8 Isolates. Starting with V8 v6.9, we enabled embedded builtins on x64. V8 v7.0 brings these memory savings to all remaining platforms except ia32.&lt;/p&gt;
&lt;h2 id=&quot;a-preview-of-webassembly-threads&quot;&gt;A preview of WebAssembly Threads &lt;a class=&quot;bookmark&quot; href=&quot;#a-preview-of-webassembly-threads&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;WebAssembly (Wasm) enables compilation of code written in C++ and other languages to run on the web. One very useful feature of native applications is the ability to use threads — a primitive for parallel computation. Most C and C++ developers would be familiar with pthreads, which is a standardized API for application thread management.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://www.w3.org/community/webassembly/&quot;&gt;WebAssembly Community Group&lt;/a&gt; has been working on bringing threads to the web to enable real multi-threaded applications. As part of this effort, V8 has implemented necessary support for threads in the WebAssembly engine. To use this feature in Chrome, you can enable it via &lt;code&gt;chrome://flags/#enable-webassembly-threads&lt;/code&gt;, or your site can sign up for an &lt;a href=&quot;https://github.com/GoogleChrome/OriginTrials&quot;&gt;Origin Trial&lt;/a&gt;. Origin Trials allow developers to experiment with new web features before they are fully standardized, and that helps us gather real-world feedback which is critical to validate and improve new features.&lt;/p&gt;
&lt;h2 id=&quot;javascript-language-features&quot;&gt;JavaScript language features &lt;a class=&quot;bookmark&quot; href=&quot;#javascript-language-features&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://tc39.github.io/proposal-Symbol-description/&quot;&gt;A &lt;code&gt;description&lt;/code&gt; property&lt;/a&gt; is being added to &lt;code&gt;Symbol.prototype&lt;/code&gt;. This provides a more ergonomic way of accessing the description of a &lt;code&gt;Symbol&lt;/code&gt;. Previously, the description could be only be accessed indirectly through &lt;code&gt;Symbol.prototype.toString()&lt;/code&gt;. Thanks to Igalia for contributing this implementation!&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Array.prototype.sort&lt;/code&gt; is now stable in V8 v7.0. Previously, V8 used an unstable QuickSort for arrays with more than 10 elements. Now, we use the stable TimSort algorithm. See &lt;a href=&quot;https://v8.js.cn/blog/array-sort&quot;&gt;our blog post&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h2 id=&quot;v8-api&quot;&gt;V8 API &lt;a class=&quot;bookmark&quot; href=&quot;#v8-api&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Please use &lt;code&gt;git log branch-heads/6.9..branch-heads/7.0 include/v8.h&lt;/code&gt; to get a list of the API changes.&lt;/p&gt;
&lt;p&gt;Developers with an &lt;a href=&quot;https://github.com/v8/v8/wiki/Using-Git&quot;&gt;active V8 checkout&lt;/a&gt; can use &lt;code&gt;git checkout -b 7.0 -t branch-heads/7.0&lt;/code&gt; to experiment with the new features in V8 v7.0. Alternatively you can &lt;a href=&quot;https://www.google.com/chrome/browser/beta.html&quot;&gt;subscribe to Chrome’s Beta channel&lt;/a&gt; and try the new features out yourself soon.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Getting things sorted in V8</title>
    <link href="https://v8.js.cn/blog/array-sort"/>
    <updated>2018-09-28T11:20:37+00:00</updated>
    <id>https://v8.js.cn/blog/array-sort</id>
    <author>
      <name>Simon Zünd (@nimODota), consistent comparator</name>
    </author>
    <content type="html">&lt;p&gt;&lt;code&gt;Array.prototype.sort&lt;/code&gt; was among the last builtins implemented in self-hosted JavaScript in V8. Porting it offered us the opportunity to experiment with different algorithms and implementation strategies and finally &lt;a href=&quot;https://mathiasbynens.be/demo/sort-stability&quot;&gt;make it stable&lt;/a&gt; in V8 v7.0 / Chrome 70.&lt;/p&gt;
&lt;h2 id=&quot;background&quot;&gt;Background &lt;a class=&quot;bookmark&quot; href=&quot;#background&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Sorting in JavaScript is hard. This blog post looks at some of the quirks in the interaction between a sorting algorithm and the JavaScript language, and describes our journey to move V8 to a stable algorithm and make performance more predictable.&lt;/p&gt;
&lt;p&gt;When comparing different sorting algorithms we look at their worst and average performance given as a bound on the asymptotic growth (i.e. “Big O” notation) of either memory operations or number of comparisons. Note that in dynamic languages, such as JavaScript, a comparison operation is usually a magnitude more expensive than a memory access. This is due to the fact that comparing two values while sorting usually involves calls to user code.&lt;/p&gt;
&lt;p&gt;Let’s take a look at a simple example of sorting some numbers into ascending order based on a user-provided comparison function. A &lt;em&gt;consistent&lt;/em&gt; comparison function returns &lt;code&gt;-1&lt;/code&gt; (or any other negative value), &lt;code&gt;0&lt;/code&gt;, or &lt;code&gt;1&lt;/code&gt; (or any other positive value) when the two provided values are either smaller, equal, or greater respectively. A comparison function that does not follow this pattern is &lt;em&gt;inconsistent&lt;/em&gt; and can have arbitrary side-effects, such as modifying the array it’s intended to sort.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; array &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;compare&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;a&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; b&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token comment&quot;&gt;// Arbitrary code goes here, e.g. `array.push(1);`.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; a &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt; b&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// A “typical” sort call.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;array&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;compare&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even in the next example, calls to user code may happen. The “default” comparison function calls &lt;code&gt;toString&lt;/code&gt; on both values and does a lexicographical comparison on the string representations.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; array &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;array&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token function&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token comment&quot;&gt;// Arbitrary code goes here, e.g. `array.push(1);`.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;42&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// Sort without a comparison function.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;array&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;accessors-prototype&quot;&gt;More fun with accessors and prototype-chain interactions &lt;a class=&quot;bookmark&quot; href=&quot;#accessors-prototype&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is the part where we leave the spec behind and venture into “implementation-defined” behavior land. The spec has a whole list of conditions that, when met, allow the engine to sort the object/array as it sees fit — or not at all. Engines still have to follow some ground rules but everything else is pretty much up in the air. On the one hand, this gives engine developers the freedom to experiment with different implementations. On the other hand, users expect some reasonable behavior even though the spec doesn’t require there to be any. This is further complicated by the fact that “reasonable behavior” is not always straightforward to determine.&lt;/p&gt;
&lt;p&gt;This section shows that there are still some aspects of &lt;code&gt;Array#sort&lt;/code&gt; where engine behavior differs greatly. These are hard edge cases, and as mentioned above it’s not always clear what “the right thing to do” actually is. We &lt;em&gt;highly&lt;/em&gt; recommend not writing code like this; engines won’t optimize for it.&lt;/p&gt;
&lt;p&gt;The first example shows an array with some accessors (i.e. getters and setters) and a “call log” in different JavaScript engines. Accessors are the first case where the resulting sort order is implementation-defined:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; array &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;Object&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;defineProperty&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;0&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; console&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;get 0&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;v&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; console&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;set 0&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;Object&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;defineProperty&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; console&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;get 1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;v&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; console&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;set 1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;array&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the output of that snippet in various engines. Note that there are no “right” or “wrong” answers here — the spec leaves this up to the implementation!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Chakra
get 0
get 1
set 0
set 1

// JavaScriptCore
get 0
get 1
get 0
get 0
get 1
get 1
set 0
set 1

// V8
get 0
get 0
get 1
get 1
get 1
get 0

#### SpiderMonkey
get 0
get 1
set 0
set 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next example shows interactions with the prototype chain. For the sake of brevity we don’t show the call log.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; object &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt; &lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt; &lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt; __proto__&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   length&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;e2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   &lt;span class=&quot;token number&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;a2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   &lt;span class=&quot;token number&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   &lt;span class=&quot;token number&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   &lt;span class=&quot;token number&quot;&gt;8000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   &lt;span class=&quot;token number&quot;&gt;12000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;XX&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   __proto__&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;     &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;e3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;     &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;     &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;     &lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;     &lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;f3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;     &lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;a3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;     &lt;span class=&quot;token number&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;Array&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;prototype&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;sort&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output shows the &lt;code&gt;object&lt;/code&gt; after it’s sorted. Again, there is no right answer here. This example just shows how weird the interaction between indexed properties and the prototype chain can get:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// Chakra&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;a2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;a3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;e3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// JavaScriptCore&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;a2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;a2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;a3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;e3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// V8&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;a2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;a3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;e3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// SpiderMonkey&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;a2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;a3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;b2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;c2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d1&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;d2&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;e3&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; undefined&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;before-sort&quot;&gt;What V8 does before actually sorting &lt;a class=&quot;bookmark&quot; href=&quot;#before-sort&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;V8 has two pre-processing steps before it actually sorts anything. First, if the object to sort has holes and elements on the prototype chain, they are copied from the prototype chain to the object itself. This frees us from caring about the prototype chain during all remaining steps. This is currently only done for non-&lt;code&gt;JSArray&lt;/code&gt;s but other engines do it for &lt;code&gt;JSArray&lt;/code&gt;s as well.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/array-sort/copy-prototype.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Copying from the prototype chain&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The second pre-processing step is the removal of holes. All elements in the sort-range are moved to the beginning of the object. &lt;code&gt;undefined&lt;/code&gt;s are moved after that. This is even required by the spec to some degree as it requires us to &lt;em&gt;always&lt;/em&gt; sort &lt;code&gt;undefined&lt;/code&gt;s to the end. The result is that a user-provided comparison function will never get called with an &lt;code&gt;undefined&lt;/code&gt; argument. After the second pre-processing step the sorting algorithm only needs to consider non-&lt;code&gt;undefined&lt;/code&gt;s, potentially reducing the number of elements it actually has to sort.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/array-sort/remove-array-holes.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Removing holes and moving &lt;code&gt;undefined&lt;/code&gt;s to the end&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;history&quot;&gt;History &lt;a class=&quot;bookmark&quot; href=&quot;#history&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Array.prototype.sort&lt;/code&gt; and &lt;code&gt;TypedArray.prototype.sort&lt;/code&gt; relied on the same Quicksort implementation written in JavaScript. The sorting algorithm itself is rather straightforward: The basis is a Quicksort with an Insertion Sort fall-back for shorter arrays (length &amp;lt; 10). The Insertion Sort fall-back was also used when Quicksort recursion reached a sub-array length of 10. Insertion Sort is more efficient for smaller arrays. This is because Quicksort gets called recursively twice after partitioning. Each such recursive call had the overhead of creating (and discarding) a stack frame.&lt;/p&gt;
&lt;p&gt;Choosing a suitable pivot element has a big impact when it comes to Quicksort. V8 employed two strategies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The pivot was chosen as the median of the first, last, and a third element of the sub-array that gets sorted. For smaller arrays that third element is simply the middle element.&lt;/li&gt;
&lt;li&gt;For larger arrays a sample was taken, then sorted and the median of the sorted sample served as the third element in the above calculation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One of the advantages of Quicksort is that it sorts in-place. The memory overhead comes from allocating a small array for the sample when sorting large arrays, and log(n) stack space. The downside is that it’s not a stable algorithm and there’s a chance the algorithm hits the worst-case scenario where QuickSort degrades to O(n^2).&lt;/p&gt;
&lt;h3 id=&quot;introducing-v8-torque&quot;&gt;Introducing V8 Torque &lt;a class=&quot;bookmark&quot; href=&quot;#introducing-v8-torque&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As an avid reader of the V8 blog you might have heard of &lt;a href=&quot;https://v8.js.cn/blog/csa&quot;&gt;&lt;code&gt;CodeStubAssembler&lt;/code&gt;&lt;/a&gt; or CSA for short. CSA is a V8 component that allows us to write low-level TurboFan IR directly in C++ that later gets translated to machine code for the appropriate architecture using TurboFan’s backend.&lt;/p&gt;
&lt;p&gt;CSA is heavily utilized to write so-called “fast-paths” for JavaScript builtins. A fast-path version of a builtin usually checks whether certain invariants hold (e.g. no elements on the prototype chain, no accessors, etc) and then uses faster, more specific operations to implement the builtin functionality. This can result in execution times that are an order of magnitude faster than a more generic version.&lt;/p&gt;
&lt;p&gt;The downside of CSA is that it really can be considered an assembly language. Control-flow is modeled using explicit &lt;code&gt;labels&lt;/code&gt; and &lt;code&gt;gotos&lt;/code&gt;, which makes implementing more complex algorithms in CSA hard to read and error-prone.&lt;/p&gt;
&lt;p&gt;Enter &lt;a href=&quot;https://v8.js.cn/docs/torque&quot;&gt;V8 Torque&lt;/a&gt;. Torque is a domain-specific language with TypeScript-like syntax that currently uses CSA as its sole compilation target. Torque allows nearly the same level of control as CSA does while at the same time offering higher-level constructs such as &lt;code&gt;while&lt;/code&gt; and &lt;code&gt;for&lt;/code&gt; loops. Additionally, it’s strongly typed and will in the future contain security checks such as automatic out-of-bound checks providing V8 engineers with stronger guarantees.&lt;/p&gt;
&lt;p&gt;The first major builtins that were re-written in V8 Torque were &lt;a href=&quot;https://v8.js.cn/blog/v8-release-68&quot;&gt;&lt;code&gt;TypedArray#sort&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://v8.js.cn/blog/dataview&quot;&gt;&lt;code&gt;Dataview&lt;/code&gt; operations&lt;/a&gt;. Both served the additional purpose of providing feedback to the Torque developers on what languages features are needed and idioms should be used to write builtins efficiently. At the time of writing, several &lt;code&gt;JSArray&lt;/code&gt; builtins had their self-hosted JavaScript fall-back implementations moved to Torque (e.g. &lt;code&gt;Array#unshift&lt;/code&gt;) while others were completely re-written (e.g. &lt;code&gt;Array#splice&lt;/code&gt; and &lt;code&gt;Array#reverse&lt;/code&gt;).&lt;/p&gt;
&lt;h3 id=&quot;moving-array%23sort-to-torque&quot;&gt;Moving &lt;code&gt;Array#sort&lt;/code&gt; to Torque &lt;a class=&quot;bookmark&quot; href=&quot;#moving-array%23sort-to-torque&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The initial &lt;code&gt;Array#sort&lt;/code&gt; Torque version was more or less a straight up port of the JavaScript implementation. The only difference was that instead of using a sampling approach for larger arrays, the third element for the pivot calculation was chosen at random.&lt;/p&gt;
&lt;p&gt;This worked reasonably well, but as it still utilized Quicksort, &lt;code&gt;Array#sort&lt;/code&gt; remained unstable. &lt;a href=&quot;https://bugs.chromium.org/p/v8/issues/detail?id=90&quot;&gt;The request for a stable &lt;code&gt;Array#sort&lt;/code&gt;&lt;/a&gt; is among the oldest tickets in V8’s bug tracker. Experimenting with Timsort as a next step offered us multiple things. First, we like that it’s stable and offers some nice algorithmic guarantees (see next section). Second, Torque was still a work-in-progress and implementing a more complex builtin such as &lt;code&gt;Array#sort&lt;/code&gt; with Timsort resulted in lots of actionable feedback influencing Torque as a language.&lt;/p&gt;
&lt;h2 id=&quot;timsort&quot;&gt;Timsort &lt;a class=&quot;bookmark&quot; href=&quot;#timsort&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Timsort, initially developed by Tim Peters for Python in 2002, could best be described as an adaptive stable Mergesort variant. Even though the details are rather complex and are best described by &lt;a href=&quot;https://github.com/python/cpython/blob/master/Objects/listsort.txt&quot;&gt;the man himself&lt;/a&gt; or the &lt;a href=&quot;https://en.wikipedia.org/wiki/Timsort&quot;&gt;Wikipedia page&lt;/a&gt;, the basics are easy to understand. While Mergesort usually works in recursive fashion, Timsort works iteratively. It processes an array from left to right and looks for so-called &lt;em&gt;runs&lt;/em&gt;. A run is simply a sequence that is already sorted. This includes sequences that are sorted “the wrong way” as these sequences can simply be reversed to form a run. At the start of the sorting process a minimum run length is determined that depends on the length of the input. If Timsort can’t find natural runs of this minimum run length a run is “boosted artificially” using Insertion Sort.&lt;/p&gt;
&lt;p&gt;Runs that are found this way are tracked using a stack that remembers a starting index and a length of each run. From time to time runs on the stack are merged together until only one sorted run remains. Timsort tries to maintain a balance when it comes to deciding which runs to merge. On the one hand you want to try and merge early as the data of those runs has a high chance of already being in the cache, on the other hand you want to merge as late as possible to take advantage of patterns in the data that might emerge. To accomplish this, Timsort maintains two invariants. Assuming &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt;, and &lt;code&gt;C&lt;/code&gt; are the three top-most runs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;|C| &amp;gt; |B| + |A|&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;|B| &amp;gt; |A|&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/array-sort/runs-stack.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Runs stack before and after merging &lt;code&gt;A&lt;/code&gt; with &lt;code&gt;B&lt;/code&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The image shows the case where &lt;code&gt;|A| &amp;gt; |B|&lt;/code&gt; so &lt;code&gt;B&lt;/code&gt; is merged with the smaller of the two runs.&lt;/p&gt;
&lt;p&gt;Note that Timsort only merges consecutive runs, this is needed to maintain stability, otherwise equal elements would be transferred between runs. Also the first invariant makes sure that run lengths grow at least as fast as the Fibonacci numbers, giving an upper bound on the size of the run stack when we know the maximum array length.&lt;/p&gt;
&lt;p&gt;One can now see that already-sorted sequences are sorted in O(n) as such an array would result in a single run that does not need to get merged. The worst case is O(n log n). These algorithmic properties together with the stable nature of Timsort were a few of the reasons why we chose Timsort over Quicksort in the end.&lt;/p&gt;
&lt;h3 id=&quot;implementing-timsort-in-torque&quot;&gt;Implementing Timsort in Torque &lt;a class=&quot;bookmark&quot; href=&quot;#implementing-timsort-in-torque&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Builtins usually have different code-paths that are chosen during runtime depending on various variables. The most generic version can handle any kind of object, regardless if its a &lt;code&gt;JSProxy&lt;/code&gt;, has interceptors or needs to do prototype chain lookups when retrieving or setting properties.&lt;br&gt;
The generic path is rather slow in most cases, as it needs to account for all eventualities. But if we know upfront that the object to sort is a simple &lt;code&gt;JSArray&lt;/code&gt; containing only Smis, all these expensive &lt;code&gt;[[Get]]&lt;/code&gt; and &lt;code&gt;[[Set]]&lt;/code&gt; operations can be replaced by simple Loads and Stores to a &lt;code&gt;FixedArray&lt;/code&gt;. The main differentiator is the &lt;a href=&quot;https://v8.js.cn/blog/elements-kinds&quot;&gt;&lt;code&gt;ElementsKind&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The problem now becomes how to implement a fast-path. The core algorithm stays the same for all but the way we access elements changes based on the &lt;code&gt;ElementsKind&lt;/code&gt;. One way we could accomplish this is to dispatch to the correct “accessor” on each call-site. Imagine a switch for each “load”/”store” operation where we choose a different branch based on the chosen fast-path.&lt;/p&gt;
&lt;p&gt;Another solution (and this was the first approach tried) is to just copy the whole builtin once for each fast-path and inline the correct load/store access method. This approach turned out to be infeasible for Timsort as it’s a big builtin and making a copy for each fast-path turned out to require 106 KB in total, which is way too much for a single builtin.&lt;/p&gt;
&lt;p&gt;The final solution is slightly different. Each load/store operation for each fast-path is put into its own “mini-builtin”. See the code example which shows the “load” operation for &lt;code&gt;FixedDoubleArray&lt;/code&gt;s.&lt;/p&gt;
&lt;pre class=&quot;language-torque&quot;&gt;&lt;code class=&quot;language-torque&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;Load&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;FastDoubleElements&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    context&lt;span class=&quot;token class-name&quot;&gt;: Context,&lt;/span&gt; sortState&lt;span class=&quot;token class-name&quot;&gt;: FixedArray,&lt;/span&gt; elements&lt;span class=&quot;token class-name&quot;&gt;: HeapObject,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    index&lt;span class=&quot;token class-name&quot;&gt;: Smi)&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;: Object {&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; elems&lt;span class=&quot;token class-name&quot;&gt;: FixedDoubleArray =&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;UnsafeCast&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;FixedDoubleArray&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;elements&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; value&lt;span class=&quot;token class-name&quot;&gt;: float64 =&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;        LoadDoubleWithHoleCheck&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;elems&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; index&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;otherwise&lt;/span&gt; Bailout&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; AllocateHeapNumberWithValue&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;label&lt;/span&gt; Bailout &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token comment&quot;&gt;// The pre-processing step removed all holes by compacting all elements&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token comment&quot;&gt;// at the start of the array. Finding a hole means the cmp function or&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token comment&quot;&gt;// ToString changes the array.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; Failure&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;sortState&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To compare, the most generic “load” operation is simply a call to &lt;code&gt;GetProperty&lt;/code&gt;. But while the above version generates efficient and fast machine code to load and convert a &lt;code&gt;Number&lt;/code&gt;, &lt;code&gt;GetProperty&lt;/code&gt; is a call to another builtin that could potentially involve a prototype chain lookup or invoke an accessor function.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;builtin Load&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;ElementsAccessor &lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; type&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    context&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; Context&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; sortState&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; FixedArray&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; elements&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; HeapObject&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    index&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; Smi&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; Object &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;GetProperty&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;context&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; elements&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; index&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A fast-path then simply becomes a set of function pointers. This means we only need one copy of the core algorithm while setting up all relevant function pointers once upfront. While this greatly reduces the needed code space (down to 20k) it comes at the cost of an indirect branch at each access site. This is even exacerbated by the recent change to use &lt;a href=&quot;https://v8.js.cn/blog/embedded-builtins&quot;&gt;embedded builtins&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;sort-state&quot;&gt;Sort state &lt;a class=&quot;bookmark&quot; href=&quot;#sort-state&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/array-sort/sort-state.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;The picture above shows the “sort state”. It’s a &lt;code&gt;FixedArray&lt;/code&gt; that keeps track of all the things needed while sorting. Each time &lt;code&gt;Array#sort&lt;/code&gt; is called, such a sort state is allocated. Entry 4 to 7 are the set of function pointers discussed above that comprise a fast-path.&lt;/p&gt;
&lt;p&gt;The “check” builtin is used every time we return from user JavaScript code, to check if we can continue on the current fast-path. It uses the “initial receiver map” and “initial receiver length” for this.  Should the user code have modified the current object, we simply abandon the sorting run, reset all pointers to their most generic version and restart the sorting process. The “bailout status” in slot 8 is used to signal this reset.&lt;/p&gt;
&lt;p&gt;The “compare” entry can point to two different builtins. One calls a user-provided comparison function while the other implements the default comparison that calls &lt;code&gt;toString&lt;/code&gt; on both arguments and then does a lexicographical comparison.&lt;/p&gt;
&lt;p&gt;The rest of the fields (with the exception of the fast path ID) are Timsort-specific. The run stack (described above) is initialized with a size of 85 which is enough to sort arrays of length 2&lt;sup&gt;64&lt;/sup&gt;. The temporary array is used for merging runs. It grows in size as needed but never exceeds &lt;code&gt;n/2&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is the input length.&lt;/p&gt;
&lt;h3 id=&quot;performance-trade-offs&quot;&gt;Performance trade-offs &lt;a class=&quot;bookmark&quot; href=&quot;#performance-trade-offs&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Moving sorting from self-hosted JavaScript to Torque comes with performance trade-offs. As &lt;code&gt;Array#sort&lt;/code&gt; is written in Torque, it’s now a statically compiled piece of code, meaning we still can build fast-paths for certain &lt;a href=&quot;https://v8.js.cn/blog/elements-kinds&quot;&gt;&lt;code&gt;ElementsKind&lt;/code&gt;s&lt;/a&gt; but it will never be as fast as a highly optimized TurboFan version that can utilize type feedback. On the other hand, in cases where the code doesn’t get hot enough to warrant JIT compilation or the call-site is megamorphic, we are stuck with the interpreter or a slow/generic version. The parsing, compiling and possible optimizing of the self-hosted JavaScript version is also an overhead that is not needed with the Torque implementation.&lt;/p&gt;
&lt;p&gt;While the Torque approach doesn’t result in the same peak performance for sorting, it does avoid performance cliffs. The result is a sorting performance that is much more predictable than it previously was. Keep in mind that Torque is very much in flux and in addition of targeting CSA it might target TurboFan in the future, allowing JIT compilation of code written in Torque.&lt;/p&gt;
&lt;h3 id=&quot;microbenchmarks&quot;&gt;Microbenchmarks &lt;a class=&quot;bookmark&quot; href=&quot;#microbenchmarks&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Before we started with &lt;code&gt;Array#sort&lt;/code&gt;, we added a lot of different micro-benchmarks to get a better understanding of the impact the re-implementation would have. The first chart shows the “normal” use case of sorting various ElementsKinds with a user-provided comparison function.&lt;/p&gt;
&lt;p&gt;Keep in mind that in these cases the JIT compiler can do a lot of work, since sorting is nearly all we do. This also allows the optimizing compiler to inline the comparison function in the JavaScript version, while we have the call overhead from the builtin to JavaScript in the Torque case. Still, we perform better in nearly all cases.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/array-sort/micro-bench-basic.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;The next chart shows the impact of Timsort when processing arrays that are already sorted completely, or have sub-sequences that are already sorted one-way or another. The chart uses Quicksort as a baseline and shows the speedup of Timsort (up to 17× in the case of “DownDown” where the array consists of two reverse-sorted sequences). As can be seen, expect in the case of random data, Timsort performs better in all other cases, even though we are sorting &lt;code&gt;PACKED_SMI_ELEMENTS&lt;/code&gt;, where Quicksort outperformed Timsort in the microbenchmark above.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/array-sort/micro-bench-presorted.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;h3 id=&quot;web-tooling-benchmark&quot;&gt;Web Tooling Benchmark &lt;a class=&quot;bookmark&quot; href=&quot;#web-tooling-benchmark&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/v8/web-tooling-benchmark&quot;&gt;Web Tooling Benchmark&lt;/a&gt; is a collection of workloads of tools usually used by web developers such as Babel and TypeScript. The chart uses JavaScript Quicksort as a baseline and compares the speedup of Timsort against it. In almost all benchmarks we retain the same performance with the exception of chai.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/array-sort/web-tooling-benchmark.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;The chai benchmark spends &lt;em&gt;a third&lt;/em&gt; of its time inside a single comparison function (a string distance calculation). The benchmark is the test suite of chai itself. Due to the data, Timsort needs some more comparisons in this case, which has a bigger impact on the overall runtime, as such a big portion of time is spent inside that particular comparison function.&lt;/p&gt;
&lt;h3 id=&quot;memory-impact&quot;&gt;Memory impact &lt;a class=&quot;bookmark&quot; href=&quot;#memory-impact&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analyzing V8 heap snapshots while browsing some 50 sites (both on mobile as well as on desktop) didn’t show any memory regressions or improvements. On the one hand, this is surprising: the switch from Quicksort to Timsort introduced the need for a temporary array for merging runs, which can grow much larger than the temporary arrays used for sampling. On the other hand, these temporary arrays are very short-lived (only for the duration of the &lt;code&gt;sort&lt;/code&gt; call) and can be allocated and discarded rather quickly in V8’s new space.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion &lt;a class=&quot;bookmark&quot; href=&quot;#conclusion&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In summary we feel much better about the algorithmic properties and the predictable performance behavior of a Timsort implemented in Torque. Timsort is available starting with V8 v7.0 and Chrome 70. Happy sorting!&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Improving `DataView` performance in V8</title>
    <link href="https://v8.js.cn/blog/dataview"/>
    <updated>2018-09-18T11:20:37+00:00</updated>
    <id>https://v8.js.cn/blog/dataview</id>
    <author>
      <name>Théotime Grohens, le savant de Data-Vue, and Benedikt Meurer (@bmeurer), professional performance pal</name>
    </author>
    <content type="html">&lt;p&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView&quot;&gt;&lt;code&gt;DataView&lt;/code&gt;s&lt;/a&gt; are one of the two possible ways to do low-level memory accesses in JavaScript, the other one being &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray&quot;&gt;&lt;code&gt;TypedArray&lt;/code&gt;s&lt;/a&gt;. Up until now, &lt;code&gt;DataView&lt;/code&gt;s were much less optimized than &lt;code&gt;TypedArray&lt;/code&gt;s in V8, resulting in lower performance on tasks such as graphics-intensive workloads or when decoding/encoding binary data. The reasons for this have been mostly historical choices, like the fact that &lt;a href=&quot;http://asmjs.org/&quot;&gt;asm.js&lt;/a&gt; chose &lt;code&gt;TypedArray&lt;/code&gt;s instead of &lt;code&gt;DataView&lt;/code&gt;s, and so engines were incentivized to focus on performance of &lt;code&gt;TypedArray&lt;/code&gt;s.&lt;/p&gt;
&lt;p&gt;Because of the performance penalty, JavaScript developers such as the Google Maps team decided to avoid &lt;code&gt;DataView&lt;/code&gt;s and rely on &lt;code&gt;TypedArray&lt;/code&gt;s instead, at the cost of increased code complexity. This article explains how we brought &lt;code&gt;DataView&lt;/code&gt; performance to match — and even surpass — equivalent &lt;code&gt;TypedArray&lt;/code&gt; code in &lt;a href=&quot;https://v8.js.cn/blog/v8-release-69&quot;&gt;V8 v6.9&lt;/a&gt;, effectively making &lt;code&gt;DataView&lt;/code&gt; usable for performance-critical real-world applications.&lt;/p&gt;
&lt;h2 id=&quot;background&quot;&gt;Background &lt;a class=&quot;bookmark&quot; href=&quot;#background&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Since the introduction of ES2015, JavaScript has supported reading and writing data in raw binary buffers called &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer&quot;&gt;&lt;code&gt;ArrayBuffer&lt;/code&gt;s&lt;/a&gt;. &lt;code&gt;ArrayBuffer&lt;/code&gt;s cannot be directly accessed; rather, programs must use a so-called &lt;em&gt;array buffer view&lt;/em&gt; object that can be either a &lt;code&gt;DataView&lt;/code&gt; or a &lt;code&gt;TypedArray&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;TypedArray&lt;/code&gt;s allow programs to access the buffer as an array of uniformly typed values, such as an &lt;code&gt;Int16Array&lt;/code&gt; or a &lt;code&gt;Float32Array&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; buffer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;ArrayBuffer&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; array &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Int16Array&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;buffer&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; array&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;length&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i&lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  array&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; i&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;console&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;array&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225]&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the other hand, &lt;code&gt;DataView&lt;/code&gt;s allow for more fine-grained data access. They let the programmer choose the type of values read from and written to the buffer by providing specialized getters and setters for each number type, making them useful for serializing data structures.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; buffer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;ArrayBuffer&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; view &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;DataView&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;buffer&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; person &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; age&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; height&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1.76&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;view&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;setUint8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; person&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;age&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;view&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;setFloat64&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; person&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;height&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;console&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;view&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;getUint8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// Expected output: 42&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;console&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;view&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;getFloat64&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// Expected output: 1.76&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Moreover, &lt;code&gt;DataView&lt;/code&gt;s also allow the choice of the endianness of the data storage, which can be useful when receiving data from external sources such as the network, a file, or a GPU.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; buffer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;ArrayBuffer&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; view &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;DataView&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;buffer&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;view&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;setInt32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0x8BADF00D&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// Little-endian write.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;console&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;view&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;getInt32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// Big-endian read.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// Expected output: 0x0DF0AD8B (233876875)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An efficient &lt;code&gt;DataView&lt;/code&gt; implementation has been a feature request for a long time (see &lt;a href=&quot;https://bugs.chromium.org/p/chromium/issues/detail?id=225811&quot;&gt;this bug report&lt;/a&gt; from over 5 years ago), and we are happy to announce that DataView performance is now on par!&lt;/p&gt;
&lt;h2 id=&quot;legacy-runtime-implementation&quot;&gt;Legacy runtime implementation &lt;a class=&quot;bookmark&quot; href=&quot;#legacy-runtime-implementation&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Until recently, the &lt;code&gt;DataView&lt;/code&gt; methods used to be implemented as built-in C++ runtime functions in V8. This is very costly, because each call would require an expensive transition from JavaScript to C++ (and back).&lt;/p&gt;
&lt;p&gt;In order to investigate the actual performance cost incurred by this implementation, we set up a performance benchmark that compares the native &lt;code&gt;DataView&lt;/code&gt; getter implementation with a JavaScript wrapper simulating &lt;code&gt;DataView&lt;/code&gt; behavior. This wrapper uses an &lt;code&gt;Uint8Array&lt;/code&gt; to read data byte by byte from the underlying buffer, and then computes the return value from those bytes. Here is, for example, the function for reading little-endian 32-bit unsigned integer values:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;LittleEndian&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;buffer&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// Simulate little-endian DataView reads.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;uint8View_ &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Uint8Array&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;buffer&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;LittleEndian&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;prototype&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function-variable function&quot;&gt;getUint32&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;byteOffset&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;uint8View_&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;byteOffset&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;uint8View_&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;byteOffset &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;uint8View_&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;byteOffset &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;uint8View_&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;byteOffset &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;TypedArray&lt;/code&gt;s are already heavily optimized in V8, so they represent the performance goal that we wanted to match.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/dataview/dataview-original.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Original &lt;code&gt;DataView&lt;/code&gt; performance&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Our benchmark shows that native &lt;code&gt;DataView&lt;/code&gt; getter performance was as much as &lt;strong&gt;4 times&lt;/strong&gt; slower than the &lt;code&gt;Uint8Array&lt;/code&gt;-based wrapper, for both big-endian and little-endian reads.&lt;/p&gt;
&lt;h2 id=&quot;improving-baseline-performance&quot;&gt;Improving baseline performance &lt;a class=&quot;bookmark&quot; href=&quot;#improving-baseline-performance&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Our first step in improving the performance of &lt;code&gt;DataView&lt;/code&gt; objects was to move the implementation from the C++ runtime to &lt;a href=&quot;https://v8.js.cn/blog/csa&quot;&gt;&lt;code&gt;CodeStubAssembler&lt;/code&gt; (also known as CSA)&lt;/a&gt;. CSA is a portable assembly language that allows us to write code directly in TurboFan’s machine-level intermediate representation (IR), and we use it to implement optimized parts of V8’s JavaScript standard library. Rewriting code in CSA bypasses the call to C++ completely, and also generates efficient machine code by leveraging TurboFan’s backend.&lt;/p&gt;
&lt;p&gt;However, writing CSA code by hand is cumbersome. Control flow in CSA is expressed much like in assembly, using explicit labels and &lt;code&gt;goto&lt;/code&gt;s, which makes the code harder to read and understand at a glance.&lt;/p&gt;
&lt;p&gt;In order to make it easier for developers to contribute to the optimized JavaScript standard library in V8, and to improve readability and maintainability, we started designing a new language called V8 &lt;em&gt;Torque&lt;/em&gt;, that compiles down to CSA. The goal for &lt;em&gt;Torque&lt;/em&gt; is to abstract away the low-level details that make CSA code harder to write and maintain, while retaining the same performance profile.&lt;/p&gt;
&lt;p&gt;Rewriting the &lt;code&gt;DataView&lt;/code&gt; code was an excellent opportunity to start using Torque for new code, and helped provide the Torque developers with a lot of feedback about the language. This is what the &lt;code&gt;DataView&lt;/code&gt;’s &lt;code&gt;getUint32()&lt;/code&gt; method looks like, written in Torque:&lt;/p&gt;
&lt;pre class=&quot;language-torque&quot;&gt;&lt;code class=&quot;language-torque&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;macro&lt;/span&gt; LoadDataViewUint32&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;buffer&lt;span class=&quot;token class-name&quot;&gt;: JSArrayBuffer,&lt;/span&gt; offset&lt;span class=&quot;token class-name&quot;&gt;: intptr,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;                    requested_little_endian&lt;span class=&quot;token class-name&quot;&gt;: bool,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;                    signed&lt;span class=&quot;token class-name&quot;&gt;: &lt;span class=&quot;token keyword&quot;&gt;constexpr&lt;/span&gt; bool)&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;: Number {&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; data_pointer&lt;span class=&quot;token class-name&quot;&gt;: RawPtr =&lt;/span&gt; buffer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;backing_store&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; b0&lt;span class=&quot;token class-name&quot;&gt;: uint32 =&lt;/span&gt; LoadUint8&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;data_pointer&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; offset&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; b1&lt;span class=&quot;token class-name&quot;&gt;: uint32 =&lt;/span&gt; LoadUint8&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;data_pointer&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; offset &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; b2&lt;span class=&quot;token class-name&quot;&gt;: uint32 =&lt;/span&gt; LoadUint8&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;data_pointer&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; offset &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; b3&lt;span class=&quot;token class-name&quot;&gt;: uint32 =&lt;/span&gt; LoadUint8&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;data_pointer&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; offset &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; result&lt;span class=&quot;token class-name&quot;&gt;: uint32;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;requested_little_endian&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    result &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;b3 &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;b2 &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;b1 &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; b0&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    result &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;b0 &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;b1 &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;b2 &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; b3&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; convert&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;Number&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;result&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Moving the &lt;code&gt;DataView&lt;/code&gt; methods to Torque already showed a &lt;strong&gt;3× improvement&lt;/strong&gt; in performance, but did not quite match &lt;code&gt;Uint8Array&lt;/code&gt;-based wrapper performance yet.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/dataview/dataview-torque.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Torque &lt;code&gt;DataView&lt;/code&gt; performance&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;optimizing-for-turbofan&quot;&gt;Optimizing for TurboFan &lt;a class=&quot;bookmark&quot; href=&quot;#optimizing-for-turbofan&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When JavaScript code gets hot, we compile it using our TurboFan optimizing compiler, in order to generate highly-optimized machine code that runs more efficiently than interpreted bytecode.&lt;/p&gt;
&lt;p&gt;TurboFan works by translating the incoming JavaScript code into an internal graph representation (more precisely, &lt;a href=&quot;https://darksi.de/d.sea-of-nodes/&quot;&gt;a “sea of nodes”&lt;/a&gt;). It starts with high-level nodes that match the JavaScript operations and semantics, and gradually refines them into lower and lower level nodes, until it finally generates machine code.&lt;/p&gt;
&lt;p&gt;In particular, a function call, such as calling one of the &lt;code&gt;DataView&lt;/code&gt; methods, is internally represented as a &lt;code&gt;JSCall&lt;/code&gt; node, which eventually boils down to an actual function call in the generated machine code.&lt;/p&gt;
&lt;p&gt;However, TurboFan allows us to check whether the &lt;code&gt;JSCall&lt;/code&gt; node is actually a call to a known function, for example one of the builtin functions, and inline this node in the IR. This means that the complicated &lt;code&gt;JSCall&lt;/code&gt; gets replaced at compile-time by a subgraph that represents the function. This allows TurboFan to optimize the inside of the function in subsequent passes as part of a broader context, instead of on its own, and most importantly to get rid of the costly function call.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/dataview/dataview-turbofan-initial.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Initial TurboFan &lt;code&gt;DataView&lt;/code&gt; performance&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Implementing TurboFan inlining finally allowed us to match, and even exceed, the performance of our &lt;code&gt;Uint8Array&lt;/code&gt; wrapper, and be &lt;strong&gt;8 times&lt;/strong&gt; as fast as the former C++ implementation.&lt;/p&gt;
&lt;h2 id=&quot;further-turbofan-optimizations&quot;&gt;Further TurboFan optimizations &lt;a class=&quot;bookmark&quot; href=&quot;#further-turbofan-optimizations&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Looking at the machine code generated by TurboFan after inlining the &lt;code&gt;DataView&lt;/code&gt; methods, there was still room for some improvement. The first implementation of those methods tried to follow the standard pretty closely, and threw errors when the spec indicates so (for example, when trying to read or write out of the bounds of the underlying &lt;code&gt;ArrayBuffer&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;However, the code that we write in TurboFan is meant to be optimized to be as fast as possible for the common, hot cases — it doesn’t need to support every possible edge case. By removing all the intricate handling of those errors, and just deoptimizing back to the baseline Torque implementation when we need to throw, we were able to reduce the size of the generated code by around 35%, generating a quite noticeable speedup, as well as considerably simpler TurboFan code.&lt;/p&gt;
&lt;p&gt;Following up on this idea of being as specialized as possible in TurboFan, we also removed support for indices or offsets that are too large (outside of Smi range) inside the TurboFan-optimized code. This allowed us to get rid of handling of the float64 arithmetic that is needed for offsets that do not fit into a 32-bit value, and to avoid storing large integers on the heap.&lt;/p&gt;
&lt;p&gt;Compared to the initial TurboFan implementation, this more than doubled the &lt;code&gt;DataView&lt;/code&gt; benchmark score. &lt;code&gt;DataView&lt;/code&gt;s are now up to 3 times as fast as the &lt;code&gt;Uint8Array&lt;/code&gt; wrapper, and around &lt;strong&gt;16 times as fast&lt;/strong&gt; as our original &lt;code&gt;DataView&lt;/code&gt; implementation!&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/dataview/dataview-turbofan-final.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Final TurboFan &lt;code&gt;DataView&lt;/code&gt; performance&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;impact&quot;&gt;Impact &lt;a class=&quot;bookmark&quot; href=&quot;#impact&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We’ve evaluated the performance impact of the new implementation on some real-world examples, on top of our own benchmark.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DataView&lt;/code&gt;s are often used when decoding data encoded in binary formats from JavaScript. One such binary format is &lt;a href=&quot;https://en.wikipedia.org/wiki/FBX&quot;&gt;FBX&lt;/a&gt;, a format that is used for exchanging 3D animations. We’ve instrumented the FBX loader of the popular &lt;a href=&quot;https://threejs.org/&quot;&gt;three.js&lt;/a&gt; JavaScript 3D library, and measured a 10% (around 80 ms) reduction in its execution time.&lt;/p&gt;
&lt;p&gt;We compared the overall performance of &lt;code&gt;DataView&lt;/code&gt;s against &lt;code&gt;TypedArray&lt;/code&gt;s. We found that our new &lt;code&gt;DataView&lt;/code&gt; implementation provides almost the same performance as &lt;code&gt;TypedArray&lt;/code&gt;s when accessing data aligned in the native endianness (little-endian on Intel processors), bridging much of the performance gap and making &lt;code&gt;DataView&lt;/code&gt;s a practical choice in V8.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/dataview/dataview-vs-typedarray.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;&lt;code&gt;DataView&lt;/code&gt; vs. &lt;code&gt;TypedArray&lt;/code&gt; peak performance&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;We hope that you’re now able to start using &lt;code&gt;DataView&lt;/code&gt;s where it makes sense, instead of relying on &lt;code&gt;TypedArray&lt;/code&gt; shims. Please send us feedback on your &lt;code&gt;DataView&lt;/code&gt; uses! You can reach us &lt;a href=&quot;https://crbug.com/v8/new&quot;&gt;via our bug tracker&lt;/a&gt;, via mail to &lt;a href=&quot;mailto:v8-users@googlegroups.com&quot;&gt;v8-users@googlegroups.com&lt;/a&gt;, or via &lt;a href=&quot;https://twitter.com/v8js&quot;&gt;@v8js on Twitter&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Celebrating 10 years of V8</title>
    <link href="https://v8.js.cn/blog/10-years"/>
    <updated>2018-09-11T19:00:00+00:00</updated>
    <id>https://v8.js.cn/blog/10-years</id>
    <author>
      <name>Mathias Bynens (@mathias), V8 historian</name>
    </author>
    <content type="html">&lt;p&gt;This month marks the 10-year anniversary of shipping not just Google Chrome, but also the V8 project. This post gives an overview of major milestones for the V8 project in the past 10 years as well as the years before, when the project was still secret.&lt;/p&gt;
&lt;figure&gt;
  &lt;iframe src=&quot;https://www.youtube.com/embed/G0vnrPTuxZA&quot; width=&quot;966&quot; height=&quot;543&quot;&gt;&lt;/iframe&gt;
  &lt;figcaption&gt;A visualization of the V8 code base over time, created using &lt;a href=&quot;http://gource.io/&quot;&gt;&lt;code&gt;gource&lt;/code&gt;&lt;/a&gt;.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;before-v8-shipped%3A-the-early-years&quot;&gt;Before V8 shipped: the early years &lt;a class=&quot;bookmark&quot; href=&quot;#before-v8-shipped%3A-the-early-years&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Google hired &lt;a href=&quot;https://en.wikipedia.org/wiki/Lars_Bak_%28computer_programmer%29&quot;&gt;Lars Bak&lt;/a&gt; in the autumn of &lt;strong&gt;2006&lt;/strong&gt; to build a new JavaScript engine for the Chrome web browser, which at the time was still a secret internal Google project. Lars had recently moved back to Aarhus, Denmark, from Silicon Valley. Since there was no Google office there and Lars wanted to remain in Denmark, Lars and several of the project’s original engineers began working on the project in an outbuilding on his farm. The new JavaScript runtime was christened “V8”, a playful reference to the powerful engine you can find in a classic muscle car. Later, when the V8 team had grown, the developers moved from their modest quarters to a modern office building in Aarhus, but the team took with them their singular drive and focus on building the fastest JavaScript runtime on the planet.&lt;/p&gt;
&lt;h2 id=&quot;launching-and-evolving-v8&quot;&gt;Launching and evolving V8 &lt;a class=&quot;bookmark&quot; href=&quot;#launching-and-evolving-v8&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;V8 went open-source the same day &lt;a href=&quot;https://blog.chromium.org/2008/09/welcome-to-chromium_02.html&quot;&gt;Chrome was launched&lt;/a&gt;: on September 2nd, &lt;strong&gt;2008&lt;/strong&gt;. &lt;a href=&quot;https://chromium.googlesource.com/v8/v8/+/43d26ecc3563a46f62a0224030667c8f8f3f6ceb&quot;&gt;The initial commit&lt;/a&gt; dates back to June 30th, 2008. Prior to that date, V8 development happened in a private CVS repository. Initially, V8 supported only the ia32 and ARM instruction sets and used &lt;a href=&quot;https://scons.org/&quot;&gt;SCons&lt;/a&gt; as its build system.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2009&lt;/strong&gt; saw the introduction of a brand new regular expression engine named &lt;a href=&quot;https://blog.chromium.org/2009/02/irregexp-google-chromes-new-regexp.html&quot;&gt;Irregexp&lt;/a&gt;, resulting in performance improvements for real-world regular expressions. With the introduction of an x64 port, the number of supported instruction sets increased from two to three. 2009 also marked &lt;a href=&quot;https://github.com/nodejs/node-v0.x-archive/releases/tag/v0.0.1&quot;&gt;the first release of the Node.js project&lt;/a&gt;, which embeds V8. The possibility for non-browser projects to embed V8 was &lt;a href=&quot;https://www.google.com/googlebooks/chrome/big_16.html&quot;&gt;explicitly mentioned&lt;/a&gt; in the original Chrome comic. With Node.js, it actually happened! Node.js grew to be one of the most popular JavaScript ecosystems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2010&lt;/strong&gt; witnessed a big boost in runtime performance as V8 introduced a brand-new optimizing JIT compiler. &lt;a href=&quot;https://blog.chromium.org/2010/12/new-crankshaft-for-v8.html&quot;&gt;Crankshaft&lt;/a&gt; generated machine code that was twice as fast and 30% smaller than the previous (unnamed) V8 compiler. That same year, V8 added its fourth instruction set: 32-bit MIPS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2011&lt;/strong&gt; came, and garbage collection was vastly improved. &lt;a href=&quot;https://blog.chromium.org/2011/11/game-changer-for-interactive.html&quot;&gt;A new incremental garbage collector&lt;/a&gt; drastically reduced pause times while maintaining great peak performance and low memory usage. V8 introduced the concept of Isolates, which allows embedders to spin up multiple instances of the V8 runtime in a process, paving the way for lighter-weight Web Workers in Chrome. The first of V8’s two build system migrations occurred as we transitioned from SCons to &lt;a href=&quot;https://gyp.gsrc.io/&quot;&gt;GYP&lt;/a&gt;. We implemented support for ES5 strict mode. Meanwhile, development moved from Aarhus to Munich (Germany) under new leadership with lots of cross-pollination from the original team in Aarhus.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2012&lt;/strong&gt; was a year of benchmarks for the V8 project. The team did speed sprints to optimize V8’s performance as measured through the &lt;a href=&quot;https://webkit.org/perf/sunspider/sunspider.html&quot;&gt;Sunspider&lt;/a&gt; and &lt;a href=&quot;https://krakenbenchmark.mozilla.org/&quot;&gt;Kraken&lt;/a&gt; benchmark suites. Later, we developed a new benchmark suite named &lt;a href=&quot;https://chromium.github.io/octane/&quot;&gt;Octane&lt;/a&gt; (with &lt;a href=&quot;http://www.netchain.com/Tools/v8/&quot;&gt;V8 Bench&lt;/a&gt; at its core) that brought peak performance competition to the forefront and spurred massive improvements in runtime and JIT technology in all major JS engines. One outcome of these efforts was the switch from randomized sampling to a deterministic, count-based technique for detecting “hot” functions in V8’s runtime profiler. This made it significantly less likely that some page loads (or benchmark runs) would randomly be much slower than others.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2013&lt;/strong&gt; witnessed the appearance of a low-level subset of JavaScript named &lt;a href=&quot;http://asmjs.org/&quot;&gt;asm.js&lt;/a&gt;. Since asm.js is limited to statically-typed arithmetic, function calls, and heap accesses with primitive types only, validated asm.js code could run with predictable performance. We released a new version of Octane, &lt;a href=&quot;https://blog.chromium.org/2013/11/announcing-octane-20.html&quot;&gt;Octane 2.0&lt;/a&gt; with updates to existing benchmarks as well as new benchmarks that target use cases like asm.js. Octane spurred the development of new compiler optimizations like &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42478.pdf&quot;&gt;allocation folding&lt;/a&gt; and &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43823.pdf&quot;&gt;allocation-site-based optimizations for type transitioning and pretenuring&lt;/a&gt; that vastly improved peak performance. As part of an effort we internally nicknamed “Handlepocalypse”, the V8 Handle API was completely rewritten to make it easier to use correctly and safely. Also in 2013, Chrome’s implementation of &lt;code&gt;TypedArray&lt;/code&gt;s in JavaScript was &lt;a href=&quot;https://codereview.chromium.org/13064003&quot;&gt;moved from Blink to V8&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;2014&lt;/strong&gt;, V8 moved some of the work of JIT compilation off the main thread with &lt;a href=&quot;https://blog.chromium.org/2014/02/compiling-in-background-for-smoother.html&quot;&gt;concurrent compilation&lt;/a&gt;, reducing jank and significantly improving performance. Later that year, we &lt;a href=&quot;https://github.com/v8/v8/commit/a1383e2250dc5b56b777f2057f1600537f02023e&quot;&gt;landed&lt;/a&gt; the initial version of a new optimizing compiler named TurboFan. Meanwhile, our partners helped port V8 to three new instruction set architectures: PPC, MIPS64, and ARM64. Following Chromium, V8 transitioned to yet another build system, &lt;a href=&quot;https://gn.googlesource.com/gn/#gn&quot;&gt;GN&lt;/a&gt;. The V8 testing infrastructure saw significant improvements, with a &lt;em&gt;Tryserver&lt;/em&gt; now available to test each patch on various build bots before landing. For source control, V8 migrated from SVN to Git.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2015&lt;/strong&gt; was a busy year for V8 on a number of fronts. We implemented &lt;a href=&quot;https://blog.chromium.org/2015/03/new-javascript-techniques-for-rapid.html&quot;&gt;code caching and script streaming&lt;/a&gt;, significantly speeding up web page load times. Work on our runtime system’s use of allocation mementos was &lt;a href=&quot;https://ai.google/research/pubs/pub43823&quot;&gt;published in ISMM 2015&lt;/a&gt;. Later that year, we &lt;a href=&quot;https://github.com/v8/v8/commit/7877c4e0c77b5c2b97678406eab7e9ad6eba4a4d&quot;&gt;kicked off&lt;/a&gt; the work on a new interpreter named Ignition. We experimented with the idea of subsetting JavaScript with &lt;a href=&quot;https://docs.google.com/document/d/1Qk0qC4s_XNCLemj42FqfsRLp49nDQMZ1y7fwf5YjaI4/view&quot;&gt;strong mode&lt;/a&gt; to achieve stronger guarantees and more predictable performance. We implemented strong mode behind a flag, but later found its benefits did not justify the costs. The addition of a &lt;a href=&quot;https://dev.chromium.org/developers/testing/commit-queue&quot;&gt;commit queue&lt;/a&gt; made big improvements in productivity and stability. V8’s garbage collector also began cooperating with embedders such as Blink to schedule garbage collection work during idle periods. &lt;a href=&quot;https://v8.js.cn/blog/free-garbage-collection&quot;&gt;Idle-time garbage collection&lt;/a&gt; significantly reduced observable garbage collection jank and memory consumption. In December, &lt;a href=&quot;https://github.com/titzer/v8-native-prototype&quot;&gt;the first WebAssembly prototype&lt;/a&gt; landed in V8.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;2016&lt;/strong&gt;, we shipped the last pieces of the ES2015 (previously known as “ES6”) feature set (including promises, class syntax, lexical scoping, destructuring, and more), as well as some ES2016 features. We also started rolling out the new Ignition and TurboFan pipeline, using it to &lt;a href=&quot;https://v8.js.cn/blog/v8-release-56&quot;&gt;compile and optimize ES2015 and ES2016 features&lt;/a&gt;, and shipping Ignition by default for &lt;a href=&quot;https://v8.js.cn/blog/ignition-interpreter&quot;&gt;low-end Android devices&lt;/a&gt;. Our successful work on idle-time garbage collection was presented at &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45361.pdf&quot;&gt;PLDI 2016&lt;/a&gt;. We kicked off &lt;a href=&quot;https://v8.js.cn/blog/orinoco&quot;&gt;the Orinoco project&lt;/a&gt;, a new mostly-parallel and concurrent garbage collector for V8 to reduce main thread garbage collection time. In a major refocus, we shifted our performance efforts away from synthetic micro-benchmarks and instead began to seriously measure and optimize &lt;a href=&quot;https://v8.js.cn/blog/real-world-performance&quot;&gt;real-world performance&lt;/a&gt;. For debugging, the V8 inspector was &lt;a href=&quot;https://v8.js.cn/blog/v8-release-55&quot;&gt;migrated&lt;/a&gt; from Chromium to V8, allowing any V8 embedder (and not just Chromium) to use the Chrome DevTools to debug JavaScript running in V8. The WebAssembly prototype graduated from prototype to experimental support, in coordination with other browser vendors &lt;a href=&quot;https://v8.js.cn/blog/webassembly-experimental&quot;&gt;experimental support for WebAssembly&lt;/a&gt;. V8 received &lt;a href=&quot;http://www.sigplan.org/Awards/Software/&quot;&gt;the ACM SIGPLAN Programming Languages Software Award&lt;/a&gt;. And another port was added: S390.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;2017&lt;/strong&gt;, we finally completed our multi-year overhaul of the engine, enabling the new &lt;a href=&quot;https://v8.js.cn/blog/launching-ignition-and-turbofan&quot;&gt;Ignition and TurboFan&lt;/a&gt; pipeline by default. This made it possible to later remove Crankshaft (&lt;a href=&quot;https://chromium-review.googlesource.com/c/v8/v8/+/547717&quot;&gt;130,380 deleted lines of code&lt;/a&gt;) and &lt;a href=&quot;https://chromium-review.googlesource.com/c/v8/v8/+/584773&quot;&gt;Full-codegen&lt;/a&gt; from the codebase. We launched Orinoco v1.0, including &lt;a href=&quot;https://v8.js.cn/blog/concurrent-marking&quot;&gt;concurrent marking&lt;/a&gt;, concurrent sweeping, parallel scavenging, and parallel compaction. We officially recognized Node.js as a first-class V8 embedder alongside Chromium. Since then, it’s impossible for a V8 patch to land if doing so breaks the Node.js test suite. Our infrastructure gained support for correctness fuzzing, ensuring that any piece of code produces consistent results regardless of the configuration it runs in.&lt;/p&gt;
&lt;p&gt;In an industry-wide coordinated launch, V8 &lt;a href=&quot;https://v8.js.cn/blog/v8-release-57&quot;&gt;shipped WebAssembly on-by-default&lt;/a&gt;. We implemented support for &lt;a href=&quot;https://developers.google.com/web/fundamentals/primers/modules&quot;&gt;JavaScript modules&lt;/a&gt; as well as the full ES2017 and ES2018 feature sets (including async functions, shared memory, async iteration, rest/spread properties, and RegExp features). We shipped &lt;a href=&quot;https://v8.js.cn/blog/javascript-code-coverage&quot;&gt;native support for JavaScript code coverage&lt;/a&gt;, and launched the &lt;a href=&quot;https://v8.js.cn/blog/web-tooling-benchmark&quot;&gt;Web Tooling Benchmark&lt;/a&gt; to help us measure how V8’s optimizations impact performance for real-world developer tools and the JavaScript output they generate. &lt;a href=&quot;https://v8.js.cn/blog/tracing-js-dom&quot;&gt;Wrapper tracing&lt;/a&gt; from JavaScript objects to C++ DOM objects and back allowed us to resolve long-standing memory leaks in Chrome and to handle the transitive closure of objects over the JavaScript and Blink heap efficiently. We later used this infrastructure to increase the capabilities of the heap snapshotting developer tool.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2018&lt;/strong&gt; saw an industry-wide security event upend what we thought we knew about CPU information security with the public disclosure of &lt;a href=&quot;https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html&quot;&gt;the Spectre/Meltdown vulnerabilities&lt;/a&gt;. V8 engineers performed extensive offensive research to help understand the threat for managed languages and develop mitigations. V8 shipped &lt;a href=&quot;https://v8.js.cn/docs/untrusted-code-mitigations&quot;&gt;mitigations&lt;/a&gt; against Spectre and similar side-channel attacks for embedders that run untrusted code.&lt;/p&gt;
&lt;p&gt;Recently, we shipped a baseline compiler for WebAssembly named &lt;a href=&quot;https://v8.js.cn/blog/liftoff&quot;&gt;Liftoff&lt;/a&gt; which greatly reduces startup time for WebAssembly applications while still achieving predictable performance. We shipped &lt;a href=&quot;https://v8.js.cn/blog/bigint&quot;&gt;&lt;code&gt;BigInt&lt;/code&gt;&lt;/a&gt;, a new JavaScript primitive that enables &lt;a href=&quot;https://developers.google.com/web/updates/2018/05/bigint&quot;&gt;arbitrary-precision integers&lt;/a&gt;. We implemented &lt;a href=&quot;https://v8.js.cn/blog/embedded-builtins&quot;&gt;embedded builtins&lt;/a&gt;, and made it possible to &lt;a href=&quot;https://v8.js.cn/blog/lazy-deserialization&quot;&gt;lazily deserialize them&lt;/a&gt;, significantly reducing V8’s footprint for multiple Isolates. We made it possible to &lt;a href=&quot;https://v8.js.cn/blog/background-compilation&quot;&gt;compile script bytecode on a background thread&lt;/a&gt;. We started &lt;a href=&quot;https://docs.google.com/presentation/d/12ZkJ0BZ35fKXtpM342PmKM5ZSxPt03_wsRgbsJYl3Pc&quot;&gt;the Unified V8-Blink Heap project&lt;/a&gt; to run a cross-component V8 and Blink garbage collection in sync. And the year’s not over yet…&lt;/p&gt;
&lt;h2 id=&quot;performance-ups-and-downs&quot;&gt;Performance ups and downs &lt;a class=&quot;bookmark&quot; href=&quot;#performance-ups-and-downs&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Chrome’s V8 Bench score over the years shows the performance impact of V8’s changes. (We’re using the V8 Bench because it’s one of the few benchmarks that can still run in the original Chrome beta.)&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/10-years/v8-bench.png&quot; srcset=&quot;https://v8.js.cn/_img/10-years/v8-bench@2x.png 2x&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Chrome’s &lt;a href=&quot;http://www.netchain.com/Tools/v8/&quot;&gt;V8 Bench&lt;/a&gt; score from 2008 to 2018&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Our score on this benchmark went up &lt;strong&gt;4×&lt;/strong&gt; over the last ten years!&lt;/p&gt;
&lt;p&gt;However, you might notice two performance dips over the years. Both are interesting because they correspond to significant events in V8’s history. The performance drop in 2015 happened when V8 shipped baseline versions of ES2015 features. These features were cross-cutting in the V8 code base, and we therefore focused on correctness rather than performance for their initial release. We accepted these slight speed regressions to get features to developers as quickly as possible. In early 2018, the Spectre vulnerability was disclosed, and V8 shipped mitigations to protect users against potential exploits, resulting in another regression in performance. Luckily, now that Chrome is shipping &lt;a href=&quot;https://developers.google.com/web/updates/2018/07/site-isolation&quot;&gt;Site Isolation&lt;/a&gt;, we can disable the mitigations again, bringing performance back on par.&lt;/p&gt;
&lt;p&gt;Another take-away from this chart is that it starts to level off around 2013. Does that mean V8 gave up and stopped investing in performance? Quite the opposite! The flattening of the graphs represents the V8 team’s pivot from synthetic micro-benchmarks (such as V8 Bench and Octane) to optimizing for &lt;a href=&quot;https://v8.js.cn/blog/real-world-performance&quot;&gt;real-world performance&lt;/a&gt;. V8 Bench is an old benchmark that doesn’t use any modern JavaScript features, nor does it approximate actual real-world production code. Contrast this with the more recent Speedometer benchmark suite:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/10-years/speedometer-1.png&quot; srcset=&quot;https://v8.js.cn/_img/10-years/speedometer-1@2x.png 2x&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Chrome’s &lt;a href=&quot;https://browserbench.org/Speedometer/&quot;&gt;Speedometer 1&lt;/a&gt; score from 2013 to 2018&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Although V8 Bench shows minimal improvements from 2013 to 2018, our Speedometer 1 score went up (another) &lt;strong&gt;4×&lt;/strong&gt; during this same time period. (We used Speedometer 1 because Speedometer 2 uses modern JavaScript features that weren’t yet supported in 2013.)&lt;/p&gt;
&lt;p&gt;Nowadays, we have &lt;a href=&quot;https://v8.js.cn/blog/speedometer-2&quot;&gt;even better&lt;/a&gt; &lt;a href=&quot;https://v8.js.cn/blog/web-tooling-benchmark&quot;&gt;benchmarks&lt;/a&gt; that more accurately reflect modern JavaScript apps, and on top of that, we &lt;a href=&quot;https://www.youtube.com/watch?v=xCx4uC7mn6Y&quot;&gt;actively measure and optimize for existing web apps&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary &lt;a class=&quot;bookmark&quot; href=&quot;#summary&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Although V8 was originally built for Google Chrome, it has always been a stand-alone project with a separate codebase and an embedding API that allows any program to use its JavaScript execution services. Over the last 10 years, the open nature of the project has helped it become a key technology not only for the Web Platform, but in other contexts, like Node.js. Along the way the project evolved and remain relevant despite many changes and dramatic growth.&lt;/p&gt;
&lt;p&gt;Initially, V8 supported only two instruction sets. In the last 10 years the list of supported platforms reached eight: ia32, x64, ARM, ARM64, 32- and 64-bit MIPS, 64-bit PPC, and S390. V8’s build system migrated from SCons to GYP to GN. The project moved from Denmark to Germany, and now has engineers all over the world, including in London, Mountain View, and San Francisco, with contributors outside of Google from many more places. We’ve transformed our entire JavaScript compilation pipeline from unnamed components to Full-codegen (a baseline compiler) and Crankshaft (an feedback-driven optimizing compiler) to Ignition (an interpreter) and TurboFan (a better feedback-driven optimizing compiler). V8 went from being “just” a JavaScript engine to also supporting WebAssembly. The JavaScript language itself evolved from ECMAScript 3 to ES2018; the latest V8 even implements post-ES2018 features.&lt;/p&gt;
&lt;p&gt;The story arc of Web is a long and enduring one. Celebrating Chrome and V8’s 10th birthday is a good opportunity to reflect that even though this is a big milestone, the Web Platform’s narrative has lasted for more than 25 years. We have no doubt the Web’s story will continue for at least that long in the future. We’re committed to making sure that V8, JavaScript, and WebAssembly continue to be interesting characters in that narrative. We’re excited to see what the next decade has in store. Stay tuned!&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Liftoff: a new baseline compiler for WebAssembly in V8</title>
    <link href="https://v8.js.cn/blog/liftoff"/>
    <updated>2018-08-20T15:45:12+00:00</updated>
    <id>https://v8.js.cn/blog/liftoff</id>
    <author>
      <name>Clemens Hammacher, WebAssembly compilation maestro</name>
    </author>
    <content type="html">&lt;p&gt;V8 &lt;a href=&quot;https://v8.js.cn/blog/v8-release-69&quot;&gt;v6.9&lt;/a&gt; includes Liftoff, a new baseline compiler for WebAssembly. Liftoff is now enabled by default on desktop systems. This article details the motivation to add another compilation tier and describes the implementation and performance of Liftoff.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/v8-liftoff.svg&quot; width=&quot;256&quot; height=&quot;256&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Logo for Liftoff, V8’s WebAssembly baseline compiler&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Since WebAssembly &lt;a href=&quot;https://v8.js.cn/blog/v8-release-57&quot;&gt;launched&lt;/a&gt; more than a year ago, adoption on the web has been steadily increasing. Big applications targeting WebAssembly have started to appear. For example, Epic’s &lt;a href=&quot;https://s3.amazonaws.com/mozilla-games/ZenGarden/EpicZenGarden.html&quot;&gt;ZenGarden benchmark&lt;/a&gt; comprises a 39.5 MB WebAssembly binary, and &lt;a href=&quot;https://web.autocad.com/&quot;&gt;AutoDesk&lt;/a&gt; ships as a 36.8 MB binary. Since compilation time is essentially linear in the binary size, these applications take a considerable time to start up. On many machines it’s more than 30 seconds, which does not provide a great user experience.&lt;/p&gt;
&lt;p&gt;But why does it take this long to start up a WebAssembly app, if similar JS apps start up much faster? The reason is that WebAssembly promises to deliver &lt;em&gt;predictable performance&lt;/em&gt;, so once the app is running, you can be sure to consistently meet your performance goals (e.g. rendering 60 frames per second, no audio lag or artifacts…). In order to achieve this, WebAssembly code is compiled &lt;em&gt;ahead of time&lt;/em&gt; in V8, to avoid any compilation pause introduced by a just-in-time compiler that could result in visible jank in the app.&lt;/p&gt;
&lt;h2 id=&quot;the-existing-compilation-pipeline-(turbofan)&quot;&gt;The existing compilation pipeline (TurboFan) &lt;a class=&quot;bookmark&quot; href=&quot;#the-existing-compilation-pipeline-(turbofan)&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;V8’s approach to compiling WebAssembly has relied on &lt;em&gt;TurboFan&lt;/em&gt;, the optimizing compiler we designed for JavaScript and asm.js. TurboFan is a powerful compiler with a graph-based &lt;em&gt;intermediate representation (IR)&lt;/em&gt; suitable for advanced optimizations such as strength reduction, inlining, code motion, instruction combining, and sophisticated register allocation. TurboFan’s design supports entering the pipeline very late, nearer to machine code, which bypasses many of the stages necessary for supporting JavaScript compilation. By design, transforming WebAssembly code into TurboFan’s IR (including &lt;a href=&quot;https://en.wikipedia.org/wiki/Static_single_assignment_form&quot;&gt;&lt;em&gt;SSA-construction&lt;/em&gt;&lt;/a&gt;) in a straightforward single pass is very efficient, partially due to WebAssembly’s structured control flow. Yet the backend of the compilation process still consumes considerable time and memory.&lt;/p&gt;
&lt;h2 id=&quot;the-new-compilation-pipeline-(liftoff)&quot;&gt;The new compilation pipeline (Liftoff) &lt;a class=&quot;bookmark&quot; href=&quot;#the-new-compilation-pipeline-(liftoff)&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The goal of Liftoff is to reduce startup time for WebAssembly-based apps by generating code as fast as possible. Code quality is secondary, as hot code is eventually recompiled with TurboFan anyway. Liftoff avoids the time and memory overhead of constructing an IR and generates machine code in a single pass over the bytecode of a WebAssembly function.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/liftoff/pipeline.svg&quot; alt=&quot;The Liftoff compilation pipeline is much simpler compared to the TurboFan compilation pipeline.&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;From the diagram above it is obvious that Liftoff should be able to generate code much faster than TurboFan since the pipeline only consists of two stages. In fact, the &lt;em&gt;function body decoder&lt;/em&gt; does a single pass over the raw WebAssembly bytes and interacts with the subsequent stage via callbacks, so &lt;em&gt;code generation&lt;/em&gt; is performed &lt;em&gt;while decoding and validating&lt;/em&gt; the function body. Together with WebAssembly’s &lt;em&gt;&lt;a href=&quot;https://v8.js.cn/blog/v8-release-65&quot;&gt;streaming APIs&lt;/a&gt;&lt;/em&gt;, this allows V8 to compile WebAssembly code to machine code while downloading over the network.&lt;/p&gt;
&lt;h3 id=&quot;code-generation-in-liftoff&quot;&gt;Code generation in Liftoff &lt;a class=&quot;bookmark&quot; href=&quot;#code-generation-in-liftoff&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Liftoff is a simple code generator, and fast. It performs only one pass over the opcodes of a function, generating code for each opcode, one at a time. For simple opcodes like arithmetics, this is often a single machine instruction, but can be more for others like calls. Liftoff maintains metadata about the operand stack in order to know where the inputs of each operation are currently stored. This &lt;em&gt;virtual stack&lt;/em&gt; exists only during compilation. WebAssembly’s structured control flow and validation rules guarantee that the location of these inputs can be statically determined. Thus an actual runtime stack onto which operands are pushed and popped is not necessary. During execution, each value on the virtual stack will either be held in a register or be spilled to the physical stack frame of that function. For small integer constants (generated by &lt;code&gt;i32.const&lt;/code&gt;), Liftoff only records the constant’s value in the virtual stack and does not generate any code. Only when the constant is used by a subsequent operation, it is emitted or combined with the operation, for example by directly emitting a &lt;code&gt;addl &amp;lt;reg&amp;gt;, &amp;lt;const&amp;gt;&lt;/code&gt; instruction on x64. This avoids ever loading that constant into a register, resulting in better code.&lt;/p&gt;
&lt;p&gt;Let’s go through a very simple function to see how Liftoff generates code for that.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/liftoff/example-1.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;This example function takes two parameters and returns their sum. When Liftoff decodes the bytes of this function, it first begins by initializing its internal state for the local variables according to the calling convention for WebAssembly functions. For x64, V8’s calling convention passes the two parameters in the registers &lt;em&gt;rax&lt;/em&gt; and &lt;em&gt;rdx&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;get_local&lt;/code&gt; instructions, Liftoff does not generate any code, but instead just updates its internal state to reflect that these register values are now pushed on the virtual stack. The &lt;code&gt;i32.add&lt;/code&gt; instruction then pops the two registers and chooses a register for the result value. We  cannot use any of the input registers for the result, since both registers still appear on the stack for holding the local variables. Overwriting them would change the value returned by a later &lt;code&gt;get_local&lt;/code&gt; instruction. So Liftoff picks a free register, in this case &lt;em&gt;rcx&lt;/em&gt;, and produce the sum of &lt;em&gt;rax&lt;/em&gt; and &lt;em&gt;rdx&lt;/em&gt; into that register. &lt;em&gt;rcx&lt;/em&gt; is then pushed onto the virtual stack.&lt;/p&gt;
&lt;p&gt;After the &lt;code&gt;i32.add&lt;/code&gt; instruction, the function body is finished, so Liftoff must assemble the function return. As our example function has one return value, validation requires that there must be exactly one value on the virtual stack at the end of the function body. So Liftoff generates code that moves the return value held in &lt;em&gt;rcx&lt;/em&gt; into the proper return register &lt;em&gt;rax&lt;/em&gt; and then returns from the function.&lt;/p&gt;
&lt;p&gt;For the sake of simplicity, the example above does not contain any blocks (&lt;code&gt;if&lt;/code&gt;, &lt;code&gt;loop&lt;/code&gt; …) or branches. Blocks in WebAssembly introduce control merges, since code can branch to any parent block, and if-blocks can be skipped. These merge points can be reached from different stack states. Following code, however, has to assume a specific stack state to generate code. Thus, Liftoff snapshots the current state of the virtual stack as the state which will be assumed for code following the new block (i.e. when returning to the &lt;em&gt;control level&lt;/em&gt; where we currently are). The new block will then continue with the currently active state, potentially changing where stack values or locals are stored: some might be spilled to the stack or held in other registers. When branching to another block or ending a block (which is the same as branching to the parent block), Liftoff must generate code that adapts the current state to the expected state at that point, such that the code emitted for the target we branch to finds the right values where it expects them. Validation guarantees that the height of the current virtual stack matches the height of the expected state, so Liftoff need only generate code to shuffle values between registers and/or the physical stack frame as shown below.&lt;/p&gt;
&lt;p&gt;Let’s look at an example of that.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/liftoff/example-2.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;The example above assumes a virtual stack with two values on the operand stack. Before starting the new block, the top value on the virtual stack is popped as argument to the &lt;code&gt;if&lt;/code&gt; instruction. The remaining stack value needs to be put in another register, since it is currently shadowing the first parameter, but when branching back to this state we might need to hold two different values for the stack value and the parameter. In this case Liftoff chooses to deduplicate it into the &lt;em&gt;rcx&lt;/em&gt; register. This state is then snapshotted, and the active state is modified within the block. At the end of the block, we implicitly branch back to the parent block, so we merge the current state into the snapshot by moving register &lt;em&gt;rbx&lt;/em&gt; into &lt;em&gt;rcx&lt;/em&gt; and reloading register &lt;em&gt;rdx&lt;/em&gt; from the stack frame.&lt;/p&gt;
&lt;h3 id=&quot;tiering-up-from-liftoff-to-turbofan&quot;&gt;Tiering up from Liftoff to TurboFan &lt;a class=&quot;bookmark&quot; href=&quot;#tiering-up-from-liftoff-to-turbofan&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With Liftoff and Turbofan, V8 now has two compilation tiers for WebAssembly: Liftoff as the baseline compiler for fast startup and TurboFan as optimizing compiler for maximum performance. This poses the question of how to combine the two compilers to provide the best overall user experience.&lt;/p&gt;
&lt;p&gt;For JavaScript, V8 uses the Ignition interpreter and the TurboFan compiler and employs a dynamic tier-up strategy. Each function is first executed in Ignition, and if the function becomes hot, TurboFan compiles it into highly-optimized machine code. A similar approach could also be used for Liftoff, but the tradeoffs are a bit different here:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;WebAssembly does not require type feedback to generate fast code. Where JavaScript greatly benefits from gathering type feedback, WebAssembly is statically typed, so the engine can generate optimized code right away.&lt;/li&gt;
&lt;li&gt;WebAssembly code should run &lt;em&gt;predictably&lt;/em&gt; fast, without a lengthy warm-up phase. One of the reasons applications target WebAssembly is to execute on the web &lt;em&gt;with predictable high performance&lt;/em&gt;. So we can neither tolerate running suboptimal code for too long, nor do we accept compilation pauses during execution.&lt;/li&gt;
&lt;li&gt;An important design goal of the Ignition interpreter for JavaScript is to reduce memory usage by not compiling functions at all. Yet we found that an interpreter for WebAssembly is far too slow to deliver on the goal of predictably fast performance. We did, in fact, build such an interpreter, but being 20× or more slower than compiled code, it is only useful for debugging, regardless of how much memory it saves. Given this, the engine must store compiled code anyway; in the end it should store only the most compact and most efficient code, which is TurboFan optimized code.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;From these constraints we concluded that dynamic tier-up is not the right tradeoff for V8’s implementation of WebAssembly right now, since it would increase code size and reduce performance for an indeterminate time span. Instead, we chose a strategy of &lt;em&gt;eager tier-up&lt;/em&gt;. Immediately after Liftoff compilation of a module finished, the WebAssembly engine starts background threads to generate optimized code for the module. This allows V8 to start executing code quickly (after Liftoff finished), but still have the most performant TurboFan code available as early as possible.&lt;/p&gt;
&lt;p&gt;The picture below shows the trace of compiling and executing &lt;a href=&quot;https://s3.amazonaws.com/mozilla-games/ZenGarden/EpicZenGarden.html&quot;&gt;the EpicZenGarden benchmark&lt;/a&gt;. It shows that right after Liftoff compilation we can instantiate the WebAssembly module and start executing it. TurboFan compilation still takes several more seconds, so during that tier-up period the observed execution performance gradually increases since individual TurboFan functions are used as soon as they are finished.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/liftoff/tierup-liftoff-turbofan.png&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;performance&quot;&gt;Performance &lt;a class=&quot;bookmark&quot; href=&quot;#performance&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Two metrics are interesting for evaluating the performance of the new Liftoff compiler. First we want to compare the compilation speed (i.e. time to generate code) with TurboFan. Second, we want to measure the performance of the generated code (i.e. execution speed). The first measure is the more interesting here, since the goal of Liftoff is to reduce startup time by generating code as quickly as possible. On the other hand, the performance of the generated code should still be pretty good since that code might still execute for several seconds or even minutes on low-end hardware.&lt;/p&gt;
&lt;h3 id=&quot;performance-of-generating-code&quot;&gt;Performance of generating code &lt;a class=&quot;bookmark&quot; href=&quot;#performance-of-generating-code&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;For measuring the &lt;em&gt;compiler performance&lt;/em&gt; itself, we ran a number of benchmarks and measured the raw compilation time using tracing (see picture above). We run both benchmarks on an HP Z840 machine (2 x Intel Xeon E5-2690 @2.6GHz, 24 cores, 48 threads) and on a Macbook Pro (Intel Core i7-4980HQ @2.8GHz, 4 cores, 8 threads). Note that Chrome does currently not use more than 10 background threads, so most of the cores of the Z840 machine are unused.&lt;/p&gt;
&lt;p&gt;We execute three benchmarks:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://s3.amazonaws.com/mozilla-games/ZenGarden/EpicZenGarden.html&quot;&gt;&lt;strong&gt;EpicZenGarden&lt;/strong&gt;&lt;/a&gt;: The ZenGarden demo running on the Epic framework&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://webassembly.org/demo/&quot;&gt;&lt;strong&gt;Tanks!&lt;/strong&gt;&lt;/a&gt;: A demo of the Unity engine&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://web.autocad.com/&quot;&gt;&lt;strong&gt;AutoDesk&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://pspdfkit.com/webassembly-benchmark/&quot;&gt;&lt;strong&gt;PSPDFKit&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For each benchmark, we measure the raw compilation time using the tracing output as shown above. This number is more stable than any time reported by the benchmark itself, as it does not rely on a task being scheduled on the main thread and does not include unrelated work like creating the actual WebAssembly instance.&lt;/p&gt;
&lt;p&gt;The graphs below show the results of these benchmarks. Each benchmark was executed three times, and we report the average compilation time.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/liftoff/performance-unity-macbook.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Code generation performance of Liftoff vs. TurboFan on a MacBook&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/liftoff/performance-unity-z840.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Code generation performance of Liftoff vs. TurboFan on a Z840&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;As expected, the Liftoff compiler generates code much faster both on the high-end desktop workstation as well as on the MacBook. The speedup of Liftoff over TurboFan is even bigger on the less-capable MacBook hardware.&lt;/p&gt;
&lt;h3 id=&quot;performance-of-the-generated-code&quot;&gt;Performance of the generated code &lt;a class=&quot;bookmark&quot; href=&quot;#performance-of-the-generated-code&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Even though performance of the generated code is a secondary goal, we want to preserve user experience with high performance in the startup phase, as Liftoff code might execute for several seconds before TurboFan code is finished.&lt;/p&gt;
&lt;p&gt;For measuring Liftoff code performance, we turned off tier-up in order to measure pure Liftoff execution. In this setup, we execute two benchmarks:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Unity headless benchmarks&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is a number of benchmarks running in the Unity framework. They are headless, hence can be executed in the d8 shell directly. Each benchmark reports a score, which is not necessarily proportional to the execution performance, but good enough to compare the performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://pspdfkit.com/webassembly-benchmark/&quot;&gt;&lt;strong&gt;PSPDFKit&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This benchmark reports the time it takes to perform different actions on a pdf document and the time it takes to instantiate the WebAssembly module (including compilation).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Just as before, we execute each benchmark three times and use the average of the three runs. Since the scale of the recorded numbers differs significantly between the benchmarks, we report the &lt;em&gt;relative performance of Liftoff vs. TurboFan&lt;/em&gt;. A value of &lt;em&gt;+30%&lt;/em&gt; means that Liftoff code runs 30% slower than TurboFan. Negative numbers indicate that Liftoff executes faster. Here are the results:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/liftoff/performance-unity-compile.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Liftoff Performance on Unity&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;On Unity, Liftoff code execute on average around 50% slower than TurboFan code on the desktop machine and 70% slower on the MacBook. Interestingly, there is one case (Mandelbrot Script) where Liftoff code outperforms TurboFan code. This is likely an outlier where, for example, the register allocator of TurboFan is doing poorly in a hot loop. We are investigating to see if TurboFan can be improved to handle this case better.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/liftoff/performance-pspdfkit-compile.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Liftoff Performance on PSPDFKit&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;On the PSPDFKit benchmark, Liftoff code executes 18-54% slower than optimized code, while initialization improves significantly, as expected. These numbers show that for real-world code which also interacts with the browser via JavaScript calls, the performance loss of unoptimized code is generally lower than on more computation-intensive benchmarks.&lt;/p&gt;
&lt;p&gt;And again, note that for these numbers we turned off tier-up completely, so we only ever executed Liftoff code. In production configurations, Liftoff code will gradually be replaced by TurboFan code, such that the lower performance of Liftoff code lasts only for short period of time.&lt;/p&gt;
&lt;h2 id=&quot;future-work&quot;&gt;Future work &lt;a class=&quot;bookmark&quot; href=&quot;#future-work&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After the initial launch of Liftoff, we are working to further improve startup time, reduce memory usage, and bring the benefits of Liftoff to more users. In particular, we are working on improving the following things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Port Liftoff to arm and arm64 to also use it on mobile devices.&lt;/strong&gt; Currently, Liftoff is only implemented for Intel platforms (32 and 64 bit), which mostly captures desktop use cases. In order to also reach mobile users, we will port Liftoff to more architectures.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Implement dynamic tier-up for mobile devices.&lt;/strong&gt; Since mobile devices tend to have much less memory available than desktop systems, we need to adapt our tiering strategy for these devices. Just recompiling all functions with TurboFan easily doubles the memory needed to hold all code, at least temporarily (until Liftoff code is discarded). Instead, we are experimenting with a combination of lazy compilation with Liftoff and dynamic tier-up of hot functions in TurboFan.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improve performance of Liftoff code generation.&lt;/strong&gt; The first iteration of an implementation is rarely the best one. There are several things which can be tuned to speed up the compilation speed of Liftoff even more. This will gradually happen over the next releases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improve performance of Liftoff code.&lt;/strong&gt; Apart from the compiler itself, the size and speed of the generated code can also be improved. This will also happen gradually over the next releases.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion &lt;a class=&quot;bookmark&quot; href=&quot;#conclusion&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;V8 now contains Liftoff, a new baseline compiler for WebAssembly. Liftoff vastly reduces start-up time of WebAssembly applications with a simple and fast code generator. On desktop systems, V8 still reaches maximum peak performance by recompiling all code in the background using TurboFan. Liftoff is enabled by default in V8 v6.9 (Chrome 69), and can be controlled explicitly with the &lt;code&gt;--liftoff&lt;/code&gt;/&lt;code&gt;--no-liftoff&lt;/code&gt; and &lt;code&gt;chrome://flags/#enable-webassembly-baseline&lt;/code&gt; flags in each, respectively.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Embedded builtins</title>
    <link href="https://v8.js.cn/blog/embedded-builtins"/>
    <updated>2018-08-14T13:33:37+00:00</updated>
    <id>https://v8.js.cn/blog/embedded-builtins</id>
    <author>
      <name>Jakob Gruber (@schuay)</name>
    </author>
    <content type="html">&lt;p&gt;V8 built-in functions (builtins) consume memory in every instance of V8. The builtin count, average size, and the number of V8 instances per Chrome browser tab have been growing significantly. This blog post describes how we reduced the median V8 heap size per website by 19% over the past year.&lt;/p&gt;
&lt;h2 id=&quot;background&quot;&gt;Background &lt;a class=&quot;bookmark&quot; href=&quot;#background&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;V8 ships with an extensive library of JavaScript (JS) &lt;a href=&quot;https://v8.js.cn/docs/builtin-functions&quot;&gt;built-in functions&lt;/a&gt;. Many builtins are directly exposed to JS developers as functions installed on JS built-in objects, such as &lt;code&gt;RegExp.prototype.exec&lt;/code&gt; and &lt;code&gt;Array.prototype.sort&lt;/code&gt;; other builtins implement various internal functionality. Machine code for builtins is generated by V8’s own compiler, and is loaded onto the managed heap state for every V8 Isolate upon initialization. An Isolate represents an isolated instance of the V8 engine, and every browser tab in Chrome contains at least one Isolate. Every Isolate has its own managed heap, and thus its own copy of all builtins.&lt;/p&gt;
&lt;p&gt;Back in 2015, builtins were mostly implemented in self-hosted JS, native assembly, or in C++. They were fairly small, and creating a copy for every Isolate was less problematic.&lt;/p&gt;
&lt;p&gt;Much has changed in this space over the last years.&lt;/p&gt;
&lt;p&gt;In 2016, V8 &lt;a href=&quot;https://v8.js.cn/blog/speeding-up-regular-expressions&quot;&gt;began&lt;/a&gt; experimenting with builtins implemented in &lt;a href=&quot;https://v8.js.cn/blog/csa&quot;&gt;CodeStubAssembler&lt;/a&gt; (CSA). This turned out to both be convenient (platform-independent, readable) and to produce efficient code, so CSA builtins became ubiquitous. For a variety of reasons, CSA builtins tend to produce larger code, and the size of V8 builtins roughly tripled as more and more were ported to CSA. By mid-2017, their per-Isolate overhead had grown significantly and we started thinking about a systematic solution.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/embedded-builtins/snapshot-size.png&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;V8 snapshot size (including builtins) from 2015 until 2017&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;In late 2017, we implemented &lt;a href=&quot;https://v8.js.cn/blog/lazy-deserialization&quot;&gt;lazy builtin (and bytecode handler) deserialization&lt;/a&gt; as a first step. Our initial analysis showed that most sites used less than half of all builtins. With lazy deserialization, builtins are loaded on-demand, and unused builtins are never loaded into the Isolate. Lazy deserialization was shipped in Chrome 64 with promising memory savings. But: builtin memory overhead was still linear in the number of Isolates.&lt;/p&gt;
&lt;p&gt;Then, &lt;a href=&quot;https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html&quot;&gt;Spectre&lt;/a&gt; was disclosed, and Chrome ultimately turned on &lt;a href=&quot;https://security.googleblog.com/2018/07/mitigating-spectre-with-site-isolation.html&quot;&gt;site isolation&lt;/a&gt; to mitigate its effects. Site isolation limits a Chrome renderer process to documents from a single origin. Thus, with site isolation, many browsing tabs create more renderer processes and more V8 Isolates. Even though managing per-Isolate overhead has always been important, site isolation has made it even more so.&lt;/p&gt;
&lt;h2 id=&quot;embedded-builtins&quot;&gt;Embedded builtins &lt;a class=&quot;bookmark&quot; href=&quot;#embedded-builtins&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Our goal for this project was to completely eliminate per-Isolate builtin overhead.&lt;/p&gt;
&lt;p&gt;The idea behind it was simple. Conceptually, builtins are identical across Isolates, and are only bound to an Isolate because of implementation details. If we could make builtins truly isolate-independent, we could keep a single copy in memory and share them across all Isolates. And if we could make them process-independent, they could even be shared across processes.&lt;/p&gt;
&lt;p&gt;In practice, we faced several challenges. Generated builtin code was neither isolate- nor process-independent due to embedded pointers to isolate- and process-specific data. V8 had no concept of executing generated code located outside the managed heap. Builtins had to be shared across processes, ideally by reusing existing OS mechanisms. And finally (this turned out to be the long tail), performance must not noticeably regress.&lt;/p&gt;
&lt;p&gt;The following sections describe our solution in detail.&lt;/p&gt;
&lt;h3 id=&quot;isolate--and-process-independent-code&quot;&gt;Isolate- and process-independent code &lt;a class=&quot;bookmark&quot; href=&quot;#isolate--and-process-independent-code&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Builtins are generated by V8’s compiler internal pipeline, which embeds references to heap constants (located on the Isolate’s managed heap), call targets (&lt;code&gt;Code&lt;/code&gt; objects, also on the managed heap), and to isolate- and process-specific addresses (e.g.: C runtime functions or a pointer to the Isolate itself, also called ’external references’) directly into the code. In x64 assembly, a load of such an object could look as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Load an embedded address into register rbx.
REX.W movq rbx,0x56526afd0f70
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;V8 has a moving garbage collector, and the location of the target object could change over time. Should the target be moved during collection, the GC updates the generated code to point at the new location.&lt;/p&gt;
&lt;p&gt;On x64 (and most other architectures), calls to other &lt;code&gt;Code&lt;/code&gt; objects use an efficient call instruction which specifies the call target by an offset from the current program counter (an interesting detail: V8 reserves its entire &lt;code&gt;CODE_SPACE&lt;/code&gt; on the managed heap at startup to ensure all possible Code objects remain within an addressable offset of each other). The relevant part of the calling sequence looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Call instruction located at [pc + &amp;lt;offset&amp;gt;].
call &amp;lt;offset&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/embedded-builtins/pc-relative-call.png&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;A pc-relative call&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Code objects themselves live on the managed heap and are movable. When they are moved, the GC updates the offset at all relevant call sites.&lt;/p&gt;
&lt;p&gt;In order to share builtins across processes, generated code must be immutable as well as isolate- and process-independent. Both instruction sequences above do not fulfill that requirement: they directly embed addresses in the code, and are patched at runtime by the GC.&lt;/p&gt;
&lt;p&gt;To address both issues, we introduced an indirection through a dedicated, so-called root register, which holds a pointer into a known location within the current Isolate.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/embedded-builtins/isolate-layout.png&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Isolate layout&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;V8’s &lt;code&gt;Isolate&lt;/code&gt; class contains the roots table, which itself contains pointers to root objects on the managed heap. The root register permanently holds the address of the roots table.&lt;/p&gt;
&lt;p&gt;The new, isolate- and process-independent way to load a root object thus becomes:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Load the constant address located at the given
// offset from roots.
REX.W movq rax,[kRootRegister + &amp;lt;offset&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Root heap constants can be loaded directly from the roots list as above. Other heap constants use an additional indirection through a global builtins constant pool, itself stored on the roots list:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Load the builtins constant pool, then the
// desired constant.
REX.W movq rax,[kRootRegister + &amp;lt;offset&amp;gt;]
REX.W movq rax,[rax + 0x1d7]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For &lt;code&gt;Code&lt;/code&gt; targets, we initially switched to a more involved calling sequence which loads the target &lt;code&gt;Code&lt;/code&gt; object from the global builtins constant pool as above, loads the target address into a register, and finally performs an indirect call.&lt;/p&gt;
&lt;p&gt;With these changes, generated code became isolate- and process-independent and we could begin working on sharing it between processes.&lt;/p&gt;
&lt;h2 id=&quot;sharing-across-processes&quot;&gt;Sharing across processes &lt;a class=&quot;bookmark&quot; href=&quot;#sharing-across-processes&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We initially evaluated two alternatives. Builtins could either be shared by &lt;code&gt;mmap&lt;/code&gt;-ing a data blob file into memory; or, they could be embedded directly into the binary. We took the latter approach since it had the advantage that we would automatically reuse standard OS mechanisms to share memory across processes, and the change would not require additional logic by V8 embedders such as Chrome. We were confident in this approach since &lt;a href=&quot;https://www.youtube.com/watch?v=lqE4u8s8Iik&quot;&gt;Dart’s AOT compilation&lt;/a&gt; had already successfully binary-embedded generated code.&lt;/p&gt;
&lt;p&gt;An executable binary file is split into several sections. For example, an ELF binary contains data in the &lt;code&gt;.data&lt;/code&gt; (initialized data), &lt;code&gt;.ro_data&lt;/code&gt; (initialized read-only data), and &lt;code&gt;.bss&lt;/code&gt; (uninitialized data) sections, while native executable code is placed in &lt;code&gt;.text&lt;/code&gt;. Our goal was to pack the builtins code into the &lt;code&gt;.text&lt;/code&gt; section alongside native code.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/embedded-builtins/binary-format.png&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Sections of an executable binary file&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;This was done by introducing a new build step that used V8’s internal compiler pipeline to generate native code for all builtins and output their contents in &lt;code&gt;embedded.cc&lt;/code&gt;. This file is then compiled into the final V8 binary.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/embedded-builtins/build-process.png&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;The (simplified) V8 embedded build process&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The &lt;code&gt;embedded.cc&lt;/code&gt; file itself contains both metadata and generated builtins machine code as a series of &lt;code&gt;.byte&lt;/code&gt; directives that instruct the C++ compiler (in our case, clang or gcc) to place the specified byte sequence directly into the output object file (and later the executable).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Information about embedded builtins are included in
// a metadata table.
V8_EMBEDDED_TEXT_HEADER(v8_Default_embedded_blob_)
__asm__(&amp;quot;.byte 0x65,0x6d,0xcd,0x37,0xa8,0x1b,0x25,0x7e\n&amp;quot;
[snip metadata]

// Followed by the generated machine code.
__asm__(V8_ASM_LABEL(&amp;quot;Builtins_RecordWrite&amp;quot;));
__asm__(&amp;quot;.byte 0x55,0x48,0x89,0xe5,0x6a,0x18,0x48,0x83\n&amp;quot;
[snip builtins code]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Contents of the &lt;code&gt;.text&lt;/code&gt; section are mapped into read-only executable memory at runtime, and the operating system will share memory across processes as long as it contains only position-independent code without relocatable symbols. This is exactly what we wanted.&lt;/p&gt;
&lt;p&gt;But V8’s &lt;code&gt;Code&lt;/code&gt; objects consist not only of the instruction stream, but also have various pieces of (sometimes isolate-dependent) metadata. Normal run-of-the-mill &lt;code&gt;Code&lt;/code&gt; objects pack both metadata and the instruction stream into a variable-sized &lt;code&gt;Code&lt;/code&gt; object that is located on the managed heap.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/embedded-builtins/code-on-heap.png&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;On-heap &lt;code&gt;Code&lt;/code&gt; object layout&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;As we’ve seen, embedded builtins have their native instruction stream located outside the managed heap, embedded into the &lt;code&gt;.text&lt;/code&gt; section. To preserve their metadata, each embedded builtin also has a small associated &lt;code&gt;Code&lt;/code&gt; object on the managed heap, called the &lt;em&gt;off-heap trampoline&lt;/em&gt;. Metadata is stored on the trampoline as for standard &lt;code&gt;Code&lt;/code&gt; objects, while the inlined instruction stream simply contains a short sequence which loads the address of the embedded instructions and jumps there.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/embedded-builtins/code-off-heap.png&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Off-heap &lt;code&gt;Code&lt;/code&gt; object layout&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The trampoline allows V8 to handle all &lt;code&gt;Code&lt;/code&gt; objects uniformly. For most purposes, it is irrelevant whether the given &lt;code&gt;Code&lt;/code&gt; object refers to standard code on the managed heap or to an embedded builtin.&lt;/p&gt;
&lt;h3 id=&quot;optimizing-for-performance&quot;&gt;Optimizing for performance &lt;a class=&quot;bookmark&quot; href=&quot;#optimizing-for-performance&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the solution described in previous sections, embedded builtins were essentially feature-complete, but benchmarks showed that they came with significant slowdowns. For instance, our initial solution regressed &lt;a href=&quot;https://v8.js.cn/blog/speedometer-2&quot;&gt;Speedometer 2.0&lt;/a&gt; by more than 5% overall.&lt;/p&gt;
&lt;p&gt;We began to hunt for optimization opportunities, and identified major sources of slowdowns. The generated code was slower due to frequent indirections taken to access isolate- and process-dependent objects. Root constants were loaded from the root list (1 indirection), other heap constants from the global builtins constant pool (2 indirections), and external references additionally had to be unpacked from within a heap object (3 indirections). The worst offender was our new calling sequence, which had to load the trampoline Code object, call it, only to then jump to the target address. Finally, it appears that calls between the managed heap and binary-embedded code were inherently slower, possibly due to the long jump distance interfering with the CPU’s branch prediction.&lt;/p&gt;
&lt;p&gt;Our work thus concentrated on 1. reducing indirections, and 2. improving the builtin calling sequence. To address the former, we altered the Isolate object layout to turn most object loads into a single root-relative load. The global builtins constant pool still exists, but only contains infrequently-accessed objects.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/embedded-builtins/isolate-layout-optimized.png&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Optimized Isolate layout&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Calling sequences were significantly improved on two fronts. Builtin-to-builtin calls were converted into a single pc-relative call instruction. This was not possible for runtime-generated JIT code since the pc-relative offset could exceed the maximal 32-bit value. There, we inlined the off-heap trampoline into all call sites, reducing the calling sequence from 6 to just 2 instructions.&lt;/p&gt;
&lt;p&gt;With these optimizations, we were able to limit regressions on Speedometer 2.0 to roughly 0.5%.&lt;/p&gt;
&lt;h1 id=&quot;results&quot;&gt;Results &lt;a class=&quot;bookmark&quot; href=&quot;#results&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;We evaluated the impact of embedded builtins on x64 over the top 10k most popular websites, and compared against both lazy- and eager deserialization (described above).&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/embedded-builtins/results.png&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;V8 heap size reduction vs. eager and lazy deserialization&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Whereas previously Chrome would ship with a memory-mapped snapshot that we’d deserialize on each Isolate, now the snapshot is replaced by embedded builtins that are still memory mapped but do not need to be deserialized. The cost for builtins used to be &lt;code&gt;c*(1 + n)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is the number of Isolates and &lt;code&gt;c&lt;/code&gt; the memory cost of all builtins, whereas now it’s just &lt;code&gt;c * 1&lt;/code&gt; (in practice, a small amount of per-Isolate overhead also remains for off heap trampolines).&lt;/p&gt;
&lt;p&gt;Compared against eager deserialization, we reduced the median V8 heap size by 19%. The median Chrome renderer process size per site has decreased by 4%. In absolute numbers, the 50th percentile saves 1.9 MB, the 30th percentile saves 3.4 MB, and the 10th percentile saves 6.5 MB per site.&lt;/p&gt;
&lt;p&gt;Significant additional memory savings are expected once bytecode handlers are also binary-embedded.&lt;/p&gt;
&lt;p&gt;Embedded builtins are rolling out on x64 in Chrome 69, and mobile platforms will follow in Chrome 70. Support for ia32 is expected to be released in late 2018.&lt;/p&gt;
&lt;p&gt;Note: All diagrams were generated using Vyacheslav Egorov’s awesome &lt;a href=&quot;https://mrale.ph/blog/2012/11/25/shaky-diagramming.html&quot;&gt;Shaky Diagramming&lt;/a&gt; tool.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>V8 release v6.9</title>
    <link href="https://v8.js.cn/blog/v8-release-69"/>
    <updated>2018-08-07T13:33:37+00:00</updated>
    <id>https://v8.js.cn/blog/v8-release-69</id>
    <author>
      <name>the V8 team</name>
    </author>
    <content type="html">&lt;p&gt;Every six weeks, we create a new branch of V8 as part of our &lt;a href=&quot;https://v8.js.cn/docs/release-process&quot;&gt;release process&lt;/a&gt;. Each version is branched from V8’s Git master immediately before a Chrome Beta milestone. Today we’re pleased to announce our newest branch, &lt;a href=&quot;https://chromium.googlesource.com/v8/v8.git/+log/branch-heads/6.9&quot;&gt;V8 version 6.9&lt;/a&gt;, which is in beta until its release in coordination with Chrome 69 Stable in several weeks. V8 v6.9 is filled with all sorts of developer-facing goodies. This post provides a preview of some of the highlights in anticipation of the release.&lt;/p&gt;
&lt;h2 id=&quot;memory-savings-through-embedded-built-ins&quot;&gt;Memory savings through embedded built-ins &lt;a class=&quot;bookmark&quot; href=&quot;#memory-savings-through-embedded-built-ins&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;V8 ships with an extensive library of built-in functions. Examples are methods on built-in objects such as &lt;code&gt;Array.prototype.sort&lt;/code&gt; and &lt;code&gt;RegExp.prototype.exec&lt;/code&gt;, but also a wide range of internal functionality. Because their generation takes a long time, built-in functions are compiled at build-time and serialized into a &lt;a href=&quot;https://v8.js.cn/blog/custom-startup-snapshots&quot;&gt;snapshot&lt;/a&gt;, which is later deserialized at runtime to create the initial JavaScript heap state.&lt;/p&gt;
&lt;p&gt;Built-in functions currently consume 700 KB in each Isolate (an Isolate roughly corresponds to a browser tab in Chrome). This is quite wasteful, and last year we began working on reducing this overhead. In V8 v6.4, we shipped &lt;a href=&quot;https://v8.js.cn/blog/lazy-deserialization&quot;&gt;lazy deserialization&lt;/a&gt;, ensuring that each Isolate only pays for the built-ins that it actually needs (but each Isolate still had its own copy).&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://v8.js.cn/blog/embedded-builtins&quot;&gt;Embedded built-ins&lt;/a&gt; go one step further. An embedded built-in is shared by all Isolates, and embedded into the binary itself instead of copied onto the JavaScript heap. This means that built-ins exist in memory only once regardless of how many Isolates are running, an especially useful property now that &lt;a href=&quot;https://developers.google.com/web/updates/2018/07/site-isolation&quot;&gt;Site Isolation&lt;/a&gt; has been enabled by default. With embedded built-ins, we’ve seen a median &lt;em&gt;9% reduction of the V8 heap size&lt;/em&gt; over the top 10k websites on x64. Of these sites, 50% save at least 1.2 MB, 30% save at least 2.1 MB, and 10% save 3.7 MB or more.&lt;/p&gt;
&lt;p&gt;V8 v6.9 ships with support for embedded built-ins on x64 platforms. Other platforms will follow soon in upcoming releases. For more details, see our &lt;a href=&quot;https://v8.js.cn/blog/embedded-builtins&quot;&gt;dedicated blog post&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;performance&quot;&gt;Performance &lt;a class=&quot;bookmark&quot; href=&quot;#performance&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&quot;liftoff%2C-webassembly%E2%80%99s-new-first-tier-compiler&quot;&gt;Liftoff, WebAssembly’s new first-tier compiler &lt;a class=&quot;bookmark&quot; href=&quot;#liftoff%2C-webassembly%E2%80%99s-new-first-tier-compiler&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;WebAssembly got a new baseline compiler for much faster startup of complex websites with big WebAssembly modules (such as Google Earth and AutoCAD). Depending on the hardware we are seeing speedups of more than 10×. For more details, refer to &lt;a href=&quot;https://v8.js.cn/blog/liftoff&quot;&gt;the detailed Liftoff blog post&lt;/a&gt;.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/v8-liftoff.svg&quot; width=&quot;256&quot; height=&quot;256&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Logo for Liftoff, V8’s baseline compiler for WebAssembly&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&quot;faster-dataview-operations&quot;&gt;Faster &lt;code&gt;DataView&lt;/code&gt; operations &lt;a class=&quot;bookmark&quot; href=&quot;#faster-dataview-operations&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://tc39.github.io/ecma262/#sec-dataview-objects&quot;&gt;&lt;code&gt;DataView&lt;/code&gt;&lt;/a&gt; methods have been reimplemented in V8 Torque, which spares a costly call to C++ compared to the former runtime implementation. Moreover, we now inline calls to &lt;code&gt;DataView&lt;/code&gt; methods when compiling JavaScript code in TurboFan, resulting in even better peak performance for hot code. Using &lt;code&gt;DataView&lt;/code&gt;s is now as efficient as using &lt;code&gt;TypedArray&lt;/code&gt;s, finally making &lt;code&gt;DataView&lt;/code&gt;s a viable choice in performance-critical situations. We’ll be covering this in more detail in an upcoming blog post about &lt;code&gt;DataView&lt;/code&gt;s, so stay tuned!&lt;/p&gt;
&lt;h3 id=&quot;faster-processing-of-weakmaps-during-garbage-collection&quot;&gt;Faster processing of &lt;code&gt;WeakMap&lt;/code&gt;s during garbage collection &lt;a class=&quot;bookmark&quot; href=&quot;#faster-processing-of-weakmaps-during-garbage-collection&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;V8 v6.9 reduces Mark-Compact garbage collection pause times by improving &lt;code&gt;WeakMap&lt;/code&gt; processing. Concurrent and incremental marking are now able to process &lt;code&gt;WeakMap&lt;/code&gt;s, whereas previously all this work was done in the final atomic pause of Mark-Compact GC. Since not all work can be moved outside of the pause, the GC now also does more work in parallel to further reduce pause times. These optimizations essentially halved the average pause time for Mark-Compact GCs in &lt;a href=&quot;https://github.com/v8/web-tooling-benchmark&quot;&gt;the Web Tooling Benchmark&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;WeakMap&lt;/code&gt; processing uses a fixed-point iteration algorithm that can degrade to quadratic runtime behavior in certain cases. With the new release, V8 is now able to switch to another algorithm that is guaranteed to finish in linear time if the GC does not finish within a certain number of iterations. Previously, worst-case examples could be constructed that took the GC a few seconds to finish even with a relatively small heap, while the linear algorithm finishes within a few milliseconds.&lt;/p&gt;
&lt;h2 id=&quot;v8-api&quot;&gt;V8 API &lt;a class=&quot;bookmark&quot; href=&quot;#v8-api&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Please use &lt;code&gt;git log branch-heads/6.8..branch-heads/6.9 include/v8.h&lt;/code&gt; to get a list of the API changes.&lt;/p&gt;
&lt;p&gt;Developers with an &lt;a href=&quot;https://v8.js.cn/docs/source-code#using-git&quot;&gt;active V8 checkout&lt;/a&gt; can use &lt;code&gt;git checkout -b 6.9 -t branch-heads/6.9&lt;/code&gt; to experiment with the new features in V8 v6.9. Alternatively you can &lt;a href=&quot;https://www.google.com/chrome/browser/beta.html&quot;&gt;subscribe to Chrome’s Beta channel&lt;/a&gt; and try the new features out yourself soon.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>V8 release v6.8</title>
    <link href="https://v8.js.cn/blog/v8-release-68"/>
    <updated>2018-06-21T13:33:37+00:00</updated>
    <id>https://v8.js.cn/blog/v8-release-68</id>
    <author>
      <name>the V8 team</name>
    </author>
    <content type="html">&lt;p&gt;Every six weeks, we create a new branch of V8 as part of our &lt;a href=&quot;https://v8.js.cn/docs/release-process&quot;&gt;release process&lt;/a&gt;. Each version is branched from V8’s Git master immediately before a Chrome Beta milestone. Today we’re pleased to announce our newest branch, &lt;a href=&quot;https://chromium.googlesource.com/v8/v8.git/+log/branch-heads/6.8&quot;&gt;V8 version 6.8&lt;/a&gt;, which is in beta until its release in coordination with Chrome 68 Stable in several weeks. V8 v6.8 is filled with all sorts of developer-facing goodies. This post provides a preview of some of the highlights in anticipation of the release.&lt;/p&gt;
&lt;h2 id=&quot;memory&quot;&gt;Memory &lt;a class=&quot;bookmark&quot; href=&quot;#memory&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;JavaScript functions unnecessarily kept outer functions and their metadata (known as &lt;code&gt;SharedFunctionInfo&lt;/code&gt; or &lt;code&gt;SFI&lt;/code&gt;) alive. Especially in function-heavy code that relies on short-lived IIFEs, this could lead to spurious memory leaks. Before this change, an active &lt;code&gt;Context&lt;/code&gt; (i.e. an on-heap representation of a function activation) kept the &lt;code&gt;SFI&lt;/code&gt; alive of the function that created the context:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/v8-release-68/context-jsfunction-before.png&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;By letting the &lt;code&gt;Context&lt;/code&gt; point to a &lt;code&gt;ScopeInfo&lt;/code&gt; object which contains the stripped-down information necessary for debugging, we can break the dependency on the &lt;code&gt;SFI&lt;/code&gt;.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/v8-release-68/context-jsfunction-after.png&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;We’ve already observed 3% V8 memory improvements on mobile devices over a set of top 10 pages.&lt;/p&gt;
&lt;p&gt;In parallel we have reduced the memory consumption of &lt;code&gt;SFI&lt;/code&gt;s themselves, removing unnecessary fields or compressing them where possible, and decreased their size by ~25%, with further reductions coming in future releases. We’ve observed &lt;code&gt;SFI&lt;/code&gt;s taking up 2–6% of V8 memory on typical websites even after detaching them from the context, so you should see memory improvements on code with a large number of functions.&lt;/p&gt;
&lt;h2 id=&quot;performance&quot;&gt;Performance &lt;a class=&quot;bookmark&quot; href=&quot;#performance&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&quot;array-destructuring-improvements&quot;&gt;Array destructuring improvements &lt;a class=&quot;bookmark&quot; href=&quot;#array-destructuring-improvements&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The optimizing compiler did not generate ideal code for array destructuring. For example, swapping variables using &lt;code&gt;[a, b] = [b, a]&lt;/code&gt; used to be twice as slow as &lt;code&gt;const tmp = a; a = b; b = tmp&lt;/code&gt;. Once we unblocked escape analysis to eliminate all temporary allocation, array destructuring with a temporary array is as fast as a sequence of assignments.&lt;/p&gt;
&lt;h3 id=&quot;object.assign-improvements&quot;&gt;&lt;code&gt;Object.assign&lt;/code&gt; improvements &lt;a class=&quot;bookmark&quot; href=&quot;#object.assign-improvements&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;So far &lt;code&gt;Object.assign&lt;/code&gt; had a fast path written in C++. That meant that the JavaScript-to-C++ boundary had to be crossed for each &lt;code&gt;Object.assign&lt;/code&gt; call. An obvious way to improve the builtin performance was to implement a fast path on the JavaScript side. We had two options: either implement it as an native JS builtin (which would come with some unnecessary overhead in this case), or implement it &lt;a href=&quot;https://v8.js.cn/blog/csa&quot;&gt;using CodeStubAssembler technology&lt;/a&gt; (which provides more flexibility). We went with the latter solution. The new implementation of &lt;code&gt;Object.assign&lt;/code&gt; improves the score of &lt;a href=&quot;https://chromeperf.appspot.com/report?sid=d9ea9a2ae7cd141263fde07ea90da835cf28f5c87f17b53ba801d4ac30979558&amp;amp;start_rev=550155&amp;amp;end_rev=552590&quot;&gt;Speedometer2/React-Redux by about 15%, improving the total Speedometer 2 score by 1.5%&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;typedarray.prototype.sort-improvements&quot;&gt;&lt;code&gt;TypedArray.prototype.sort&lt;/code&gt; improvements &lt;a class=&quot;bookmark&quot; href=&quot;#typedarray.prototype.sort-improvements&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;TypedArray.prototype.sort&lt;/code&gt; has two paths: a fast path, used when the user does not provide a comparison function, and a slow path for everything else. Until now, the slow path reused the implementation for &lt;code&gt;Array.prototype.sort&lt;/code&gt;, which does a lot more than is necessary for sorting &lt;code&gt;TypedArray&lt;/code&gt;s. V8 v6.8 replaces the slow path with an implementation in &lt;a href=&quot;https://v8.js.cn/blog/csa&quot;&gt;CodeStubAssembler&lt;/a&gt;. (Not directly CodeStubAssembler but a domain-specific language that is built on top of CodeStubAssembler).&lt;/p&gt;
&lt;p&gt;Performance for sorting &lt;code&gt;TypedArray&lt;/code&gt;s without a comparison function stays the same while there is a speedup of up to 2.5× when sorting using a comparison function.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/v8-release-68/typedarray-sort.png&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;webassembly&quot;&gt;WebAssembly &lt;a class=&quot;bookmark&quot; href=&quot;#webassembly&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In V8 v6.8 you can start using &lt;a href=&quot;https://docs.google.com/document/d/17y4kxuHFrVxAiuCP_FFtFA2HP5sNPsCD10KEx17Hz6M/edit&quot;&gt;trap-based bounds checking&lt;/a&gt; on Linux x64 platforms. This memory management optimization considerably improves WebAssembly’s execution speed. It’s already used in Chrome 68, and in the future more platforms will be supported incrementally.&lt;/p&gt;
&lt;h2 id=&quot;v8-api&quot;&gt;V8 API &lt;a class=&quot;bookmark&quot; href=&quot;#v8-api&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Please use &lt;code&gt;git log branch-heads/6.7..branch-heads/6.8 include/v8.h&lt;/code&gt; to get a list of the API changes.&lt;/p&gt;
&lt;p&gt;Developers with an &lt;a href=&quot;https://v8.js.cn/docs/source-code#using-git&quot;&gt;active V8 checkout&lt;/a&gt; can use &lt;code&gt;git checkout -b 6.8 -t branch-heads/6.8&lt;/code&gt; to experiment with the new features in V8 v6.8. Alternatively you can &lt;a href=&quot;https://www.google.com/chrome/browser/beta.html&quot;&gt;subscribe to Chrome’s Beta channel&lt;/a&gt; and try the new features out yourself soon.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Concurrent marking in V8</title>
    <link href="https://v8.js.cn/blog/concurrent-marking"/>
    <updated>2018-06-11T13:33:37+00:00</updated>
    <id>https://v8.js.cn/blog/concurrent-marking</id>
    <author>
      <name>Ulan Degenbaev, Michael Lippautz, and Hannes Payer — main thread liberators</name>
    </author>
    <content type="html">&lt;p&gt;This post describes the garbage collection technique called &lt;em&gt;concurrent marking&lt;/em&gt;. The optimization allows a JavaScript application to continue execution while the garbage collector scans the heap to find and mark live objects. Our benchmarks show that concurrent marking reduces the time spent marking on the main thread by 60%–70%. Concurrent marking is the last puzzle piece of the &lt;a href=&quot;https://v8.js.cn/blog/orinoco&quot;&gt;Orinoco project&lt;/a&gt; — the project to incrementally replace the old garbage collector with the new mostly concurrent and parallel garbage collector. Concurrent marking is enabled by default in Chrome 64 and Node.js v10.&lt;/p&gt;
&lt;h2 id=&quot;background&quot;&gt;Background &lt;a class=&quot;bookmark&quot; href=&quot;#background&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Marking is a phase of V8’s &lt;a href=&quot;https://en.wikipedia.org/wiki/Tracing_garbage_collection&quot;&gt;Mark-Compact&lt;/a&gt; garbage collector. During this phase the collector discovers and marks all live objects. Marking starts from the set of known live objects such as the global object and the currently active functions — the so-called roots. The collector marks the roots as live and follows the pointers in them to discover more live objects. The collector continues marking the newly discovered objects and following pointers until there are no more objects to mark. At the end of marking, all unmarked objects on the heap are unreachable from the application and can be safely reclaimed.&lt;/p&gt;
&lt;p&gt;We can think of marking as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Graph_traversal&quot;&gt;graph traversal&lt;/a&gt;. The objects on the heap are nodes of the graph. Pointers from one object to another are edges of the graph. Given a node in the graph we can find all out-going edges of that node using the &lt;a href=&quot;https://v8.js.cn/blog/fast-properties&quot;&gt;hidden class&lt;/a&gt; of the object.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/00.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Figure 1. Object graph&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;V8 implements marking using two mark-bits per object and a marking worklist. Two mark-bits encode three colors: white (&lt;code&gt;00&lt;/code&gt;), grey (&lt;code&gt;10&lt;/code&gt;), and black (&lt;code&gt;11&lt;/code&gt;). Initially all objects are white, which means that the collector has not discovered them yet. A white object becomes grey when the collector discovers it and pushes it onto the marking worklist. A grey object becomes black when the collector pops it from the marking worklist and visits all its fields. This scheme is called tri-color marking. Marking finishes when there are no more grey objects. All the remaining white objects are unreachable and can be safely reclaimed.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/01.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Figure 2. Marking starts from the roots&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/02.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Figure 3. The collector turns a grey object into black by processing its pointers&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/03.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Figure 4. The final state after marking is finished&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Note that the marking algorithm described above works only if the application is paused while marking is in progress. If we allow the application to run during marking, then the application can change the graph and eventually trick the collector into freeing live objects.&lt;/p&gt;
&lt;h2 id=&quot;reducing-marking-pause&quot;&gt;Reducing marking pause &lt;a class=&quot;bookmark&quot; href=&quot;#reducing-marking-pause&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Marking performed all at once can take several hundred milliseconds for large heaps.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/04.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;Such long pauses can make applications unresponsive and result in poor user experience. In 2011 V8 switched from the stop-the-world marking to incremental marking. During incremental marking the garbage collector splits up the marking work into smaller chunks and allows the application to run between the chunks:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/05.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;The garbage collector chooses how much incremental marking work to perform in each chunk to match the rate of allocations by the application. In common cases this greatly improves the responsiveness of the application. For large heaps under memory pressure there can still be long pauses as the collector tries to keep up with the allocations.&lt;/p&gt;
&lt;p&gt;Incremental marking does not come for free. The application has to notify the garbage collector about all operations that change the object graph. V8 implements the notification using a Dijkstra-style write-barrier. After each write operation of the form &lt;code&gt;object.field = value&lt;/code&gt; in JavaScript, V8 inserts the write-barrier code:&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// Called after `object.field = value`.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token function&quot;&gt;write_barrier&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; field_offset&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; black &lt;span class=&quot;token operator&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; white&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token function&quot;&gt;set_color&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; grey&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    marking_worklist&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The write-barrier enforces the invariant that no black object points to a white object. This is also known as the strong tri-color invariant and guarantees that the application cannot hide a live object from the garbage collector, so all white objects at the end of marking are truly unreachable for the application and can be safely freed.&lt;/p&gt;
&lt;p&gt;Incremental marking integrates nicely with idle time garbage collection scheduling as described in an &lt;a href=&quot;https://v8.js.cn/blog/free-garbage-collection&quot;&gt;earlier blog post&lt;/a&gt;. Chrome’s Blink task scheduler can schedule small incremental marking steps during idle time on the main thread without causing jank. This optimization works really well if idle time is available.&lt;/p&gt;
&lt;p&gt;Because of the write-barrier cost, incremental marking may reduce throughput of the application. It is possible to improve both throughput and pause times by making use of additional worker threads. There are two ways to do marking on worker threads: parallel marking and concurrent marking.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Parallel&lt;/strong&gt; marking happens on the main thread and the worker threads. The application is paused throughout the parallel marking phase. It is the multi-threaded version of the stop-the-world marking.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/06.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Concurrent&lt;/strong&gt; marking happens mostly on the worker threads. The application can continue running while concurrent marking is in progress.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/07.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;The following two sections describe how we added support for parallel and concurrent marking in V8.&lt;/p&gt;
&lt;h2 id=&quot;parallel-marking&quot;&gt;Parallel marking &lt;a class=&quot;bookmark&quot; href=&quot;#parallel-marking&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;During parallel marking we can assume that the application is not running concurrently. This substantially simplifies the implementation because we can assume that the object graph is static and does not change. In order to mark the object graph in parallel, we need to make the garbage collector data structures thread-safe and find a way to efficiently share marking work between threads. The following diagram shows the data-structures involved in parallel marking. The arrows indicate the direction of data flow. For simplicity, the diagram omits data-structures that are needed for heap defragmentation.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/08.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Figure 5. Data structures for parallel marking&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Note that the threads only read from the object graph and never change it. The mark-bits of the objects and the marking worklist have to support read and write accesses.&lt;/p&gt;
&lt;h2 id=&quot;marking-worklist-and-work-stealing&quot;&gt;Marking worklist and work stealing &lt;a class=&quot;bookmark&quot; href=&quot;#marking-worklist-and-work-stealing&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The implementation of the marking worklist is critical for performance and balances fast thread-local performance with how much work can be distributed to other threads in case they run out of work to do.&lt;/p&gt;
&lt;p&gt;The extreme sides in that trade-off space are (a) using a completely concurrent data structure for best sharing as all objects can potentially be shared and (b) using a completely thread-local data structure where no objects can be shared, optimizing for thread-local throughput. Figure 6 shows how V8 balances these needs by using a marking worklist that is based on segments for thread-local insertion and removal. Once a segment becomes full it is published to a shared global pool where it is available for stealing. This way V8 allows marking threads to operate locally without any synchronization as long as possible and still handle cases where a single thread reaches a new sub-graph of objects while another thread starves as it completely drained its local segments.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/09.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Figure 6. Marking worklist&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;concurrent-marking&quot;&gt;Concurrent marking &lt;a class=&quot;bookmark&quot; href=&quot;#concurrent-marking&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Concurrent marking allows JavaScript to run on the main thread while worker threads are visiting objects on the heap. This opens the door for many potential data races. For example, JavaScript may be writing to an object field at the same time as a worker thread is reading the field. The data races may confuse the garbage collector to free a live object or to mix up primitive values with pointers.&lt;/p&gt;
&lt;p&gt;Each operation on the main thread that changes the object graph is a potential source of a data race. Since V8 is a high-performance engine with many object layout optimizations, the list of potential data race sources is rather long. Here is a high-level breakdown:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Object allocation.&lt;/li&gt;
&lt;li&gt;Write to an object field.&lt;/li&gt;
&lt;li&gt;Object layout changes.&lt;/li&gt;
&lt;li&gt;Deserialization from the snapshot.&lt;/li&gt;
&lt;li&gt;Materialization during deoptimization of a function.&lt;/li&gt;
&lt;li&gt;Evacuation during young generation garbage collection.&lt;/li&gt;
&lt;li&gt;Code patching.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The main thread needs to synchronize with the worker threads on these operations. The cost and complexity of synchronization depends on the operation. Most operations allow lightweight synchronization with atomic memory accesses, but a few operations require exclusive access to the object. In the following subsections we highlight some of the interesting cases.&lt;/p&gt;
&lt;h3 id=&quot;write-barrier&quot;&gt;Write barrier &lt;a class=&quot;bookmark&quot; href=&quot;#write-barrier&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The data race caused by a write to an object field is resolved by turning the write operation into a &lt;a href=&quot;https://en.cppreference.com/w/cpp/atomic/memory_order#Relaxed_ordering&quot;&gt;relaxed atomic write&lt;/a&gt; and tweaking the write barrier:&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// Called after atomic_relaxed_write(&amp;amp;object.field, value);&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token function&quot;&gt;write_barrier&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; field_offset&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; white &lt;span class=&quot;token operator&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;atomic_color_transition&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; white&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; grey&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    marking_worklist&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare it with the previously-used write barrier:&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// Called after `object.field = value`.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token function&quot;&gt;write_barrier&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; field_offset&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; black &lt;span class=&quot;token operator&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; white&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token function&quot;&gt;set_color&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; grey&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    marking_worklist&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are two changes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The color check of the source object (&lt;code&gt;color(object) == black&lt;/code&gt;) is gone.&lt;/li&gt;
&lt;li&gt;The color transition of the &lt;code&gt;value&lt;/code&gt; from white to grey happens atomically.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Without the source object color check the write barrier becomes more conservative, i.e. it may mark objects as live even if those objects are not really reachable. We removed the check to avoid an expensive memory fence that would be needed between the write operation and the write barrier:&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token function&quot;&gt;atomic_relaxed_write&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;field&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token function&quot;&gt;memory_fence&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token function&quot;&gt;write_barrier&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; field_offset&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; value&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Without the memory fence the object color load operation can be reordered before the write operation. If we don’t prevent the reordering, then the write barrier may observe grey object color and bail out, while a worker thread marks the object without seeing the new value. The original write barrier proposed by Dijkstra et al. also does not check the object color. They did it for simplicity, but we need it for correctness.&lt;/p&gt;
&lt;h3 id=&quot;bailout-worklist&quot;&gt;Bailout worklist &lt;a class=&quot;bookmark&quot; href=&quot;#bailout-worklist&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Some operations, for example code patching, require exclusive access to the object. Early on we decided to avoid per-object locks because they can lead to the priority inversion problem, where the main thread has to wait for a worker thread that is descheduled while holding an object lock. Instead of locking an object, we allow the worker thread to bailout from visiting the object. The worker thread does that by pushing the object into the bailout worklist, which is processed only by the main thread:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/10.svg&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Figure 7. The bailout worklist&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Worker threads bail out on optimized code objects, hidden classes and weak collections because visiting them would require locking or expensive synchronization protocol.&lt;/p&gt;
&lt;p&gt;In retrospect, the bailout worklist turned out to be great for incremental development. We started implementation with worker threads bailing out on all object types and added concurrency one by one.&lt;/p&gt;
&lt;h3 id=&quot;object-layout-changes&quot;&gt;Object layout changes &lt;a class=&quot;bookmark&quot; href=&quot;#object-layout-changes&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A field of an object can store three kinds of values: a tagged pointer, a tagged small integer (also known as a Smi), or an untagged value like an unboxed floating-point number. &lt;a href=&quot;https://en.wikipedia.org/wiki/Tagged_pointer&quot;&gt;Pointer tagging&lt;/a&gt; is a well-known technique that allows efficient representation of unboxed integers. In V8 the least significant bit of a tagged value indicates whether it is a pointer or an integer. This relies on the fact that pointers are word-aligned. The information about whether a field is tagged or untagged is stored in the hidden class of the object.&lt;/p&gt;
&lt;p&gt;Some operations in V8 change an object field from tagged to untagged (or vice versa) by transitioning the object to another hidden class. Such an object layout change is unsafe for concurrent marking. If the change happens while a worker thread is visiting the object concurrently using the old hidden class, then two kinds of bugs are possible. First, the worker may miss a pointer thinking that it is an untagged value. The write barrier protects against this kind of bug. Second, the worker may treat an untagged value as a pointer and dereference it, which would result in an invalid memory access typically followed by a program crash. In order to handle this case we use a snapshotting protocol that synchronizes on the mark-bit of the object. The protocol involves two parties: the main thread changing an object field from tagged to untagged and the worker thread visiting the object. Before changing the field, the main thread ensures that the object is marked as black and pushes it into the bailout worklist for visiting later on:&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token function&quot;&gt;atomic_color_transition&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; white&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; grey&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;atomic_color_transition&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; grey&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; black&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token comment&quot;&gt;// The object will be revisited on the main thread during draining&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token comment&quot;&gt;// of the bailout worklist.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  bailout_worklist&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token function&quot;&gt;unsafe_object_layout_change&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As shown in the code snippet below, the worker thread first loads the hidden class of the object and snapshots all the pointer fields of the object specified by the hidden class using &lt;a href=&quot;https://en.cppreference.com/w/cpp/atomic/memory_order#Relaxed_ordering&quot;&gt;atomic relaxed load operations&lt;/a&gt;. Then it tries to mark the object black using an atomic compare and swap operation. If marking succeeded then this means that the snapshot must be consistent with the hidden class because the main thread marks the object black before changing its layout.&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;snapshot &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;hidden_class &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;atomic_relaxed_load&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;hidden_class&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;field_offset in &lt;span class=&quot;token function&quot;&gt;pointer_field_offsets&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hidden_class&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  pointer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;atomic_relaxed_load&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; field_offset&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  snapshot&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;field_offset&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; pointer&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;atomic_color_transition&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;object&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; grey&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; black&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token function&quot;&gt;visit_pointers&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;snapshot&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that a white object that undergoes an unsafe layout change has to be marked on the main thread. Unsafe layout changes are relatively rare, so this does not have a big impact on performance of real world applications.&lt;/p&gt;
&lt;h2 id=&quot;putting-it-all-together&quot;&gt;Putting it all together &lt;a class=&quot;bookmark&quot; href=&quot;#putting-it-all-together&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We integrated concurrent marking into the existing incremental marking infrastructure. The main thread initiates marking by scanning the roots and filling the marking worklist. After that it posts concurrent marking tasks on the worker threads. The worker threads help the main thread to make faster marking progress by cooperatively draining the marking worklist. Once in a while the main thread participates in marking by processing the bailout worklist and the marking worklist. Once the marking worklists become empty, the main thread finalizes garbage collection. During finalization the main thread re-scans the roots and may discover more white objects. Those objects are marked in parallel with the help of worker threads.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/11.svg&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;results&quot;&gt;Results &lt;a class=&quot;bookmark&quot; href=&quot;#results&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Our &lt;a href=&quot;https://v8.js.cn/blog/real-world-performance&quot;&gt;real-world benchmarking framework&lt;/a&gt; shows about 65% and 70% reduction in main thread marking time per garbage collection cycle on mobile and desktop respectively.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/concurrent-marking/12.png&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;Concurrent marking also reduces garbage collection jank in Node.js. This is particularly important since Node.js never implemented idle time garbage collection scheduling and therefore was never able to hide marking time in non-jank-critical phases. Concurrent marking shipped in Node.js v10.&lt;/p&gt;
</content>
  </entry>
</feed>
